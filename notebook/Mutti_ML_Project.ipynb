{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font size=\"5\"><div style=\"text-align: center\"> BCG Machine Learning Project </div></font>\n",
    "\n",
    "\n",
    "## Giacomo Mutti \n",
    "## Student ID: 10529894 \n",
    "\n",
    "## **Table of contents**\n",
    "\n",
    "1. [**Introduction**](#section_1)\n",
    "2. [**Exploratory Data Analysis**](#section_2)\n",
    "3. [**Clustering**](#section_3)\n",
    "4. [**Classification**](#section_4)\n",
    "5. [**Regression**](#section_5)\n",
    "6. [**Classification with SOD1**](#section_6)\n",
    "7. [**Discussion**](#section_7)\n",
    "\n",
    "\n",
    "<a id='section_1'></a>\n",
    "## 1. Introduction\n",
    "\n",
    "This dataset comes from the Higuera et al. 2015 paper ['Self-Organizing Feature Maps Identify Proteins Critical to Learning in a Mouse Model of Down Syndrome'](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0129126). In this study 77 protein expression levels were measured in 8 different classes of mice to assess the effect of such proteins in the learning process especially in Down Syndrome (DS). The expression levels were measured through reverse phase protein arrays (RPPA), this technique allows for high-throughput and very sensitive protein expression levels detection. So we can reasonably assume that these data are reliable and that the quantities properly reflect the actual values. The assay was performed on the nuclear fraction of the cortex of 72 mice (this dataset consists of 367 train observation and 245 test observations though).\n",
    "\n",
    "Mice were divided in 8 class based on 3 dichotomous criteria [(vd Fig 1.1)](#fig1.1):\n",
    " 1. *Down syndrome (t) or control (c)*\n",
    " 2. *Context shock (CS) or shock context (SC)*\n",
    " 3. *memantine drug (m) or saline injection (s)*\n",
    " \n",
    "The data were collected on brain lysates of 3 months old Ts65Dn Down model mice (t) and their littermate wild type (c) to control for the effect of the trisomy.\n",
    "Some of these mice were injected with memantine (m). This drug is currently in use to cure Alzheimer's disease and it seems like a suggesting molecule to solve some learning deficit also in DS. The rest of the mice were injected with a saline solution to control for the effect of the drug. Finally mice were also divided by which learning context they were exposed to. CS if the shock is given after the mice explores the cage (in this case wild type mice learn to associate the context with the shock). SC if the shock is immediately given before the mouse is allowed to explore the cage (in these cases the context should not be associated to the punishment).\n",
    "\n",
    "Theoretically the mice that will learn will be C-cs, in t-CS-m the learning will be rescued thanks to the drug and t-cs-s would fail to learn. All the SC mice should not learn.\n",
    "\n",
    "It is important to note that there are no missing values however the test data completely miss the measurement of the protein SOD1 because of a malfunctioning in the analysis.\n",
    "<a id='fig1.1'></a>\n",
    "#### Fig.1.1"
   ]
  },
  {
   "attachments": {
    "mice.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![mice.png](attachment:mice.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section_2'></a>\n",
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.stats.multitest as multi\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from pandas.plotting import parallel_coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we import the dataset. Most notably we convert the class variable as categorical. Then we create a dataset with all the possible categories as features because it may be useful. Also we prepare the data for the classification and we create a dictionary that will allow us to decode the numeric labels given to the classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read the data and creates a pandas DataFrame\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "train['class'] = pd.Categorical(train['class'])\n",
    "test['class'] = pd.Categorical(test['class'])\n",
    "# Print the first few raws of the dataset\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "# how to deal with missing SOD1_n feature in test data??\n",
    "# -> remove it from training if not really important\n",
    "# -> other ideas\n",
    "\n",
    "full_train = train.copy()\n",
    "full_train['learn_stim'] = np.where(full_train['class'].str.contains('CS'), 1, 0)\n",
    "# 1 = context shock 0 = Shock Context\n",
    "full_train['memantine'] = np.where(full_train['class'].str.contains('m'), 1, 0) \n",
    "# 1 = memantine 0 = saline\n",
    "full_train['status'] = np.where(full_train['class'].str.contains('t'), 1, 0)\n",
    "# 1 = trisomic 0 = control\n",
    "def label_learning (row):\n",
    "    if row['class'] in (['c-CS-m','c-CS-s']) :\n",
    "        return 'Normal'\n",
    "    if row['class'] in (['t-CS-s']) :\n",
    "        return 'Failed'\n",
    "    if row['class'] in (['t-CS-m']) :\n",
    "        return 'Rescued'\n",
    "    if row['class'] in (['t-SC-m','t-SC-s','c-SC-m','c-SC-s']) :\n",
    "        return 'No'\n",
    "\n",
    "full_train['actual_learning'] = full_train.apply(\n",
    "    lambda row: label_learning(row), axis=1)\n",
    "    \n",
    "# scikit api datasets\n",
    "\n",
    "X = np.array( train.drop('class', axis=1)) #the floating point values\n",
    "y = np.array(train['class'].cat.codes) #unsigned integers specifying group\n",
    "y_cat = np.array(train['class'])\n",
    "\n",
    "\n",
    "label_dict = { np.unique(y)[k] : np.unique(y_cat)[k] \n",
    "              for k in range(len(np.unique(y_cat)))}\n",
    "\n",
    "train2 = train.drop(\"SOD1_N\", axis=1)\n",
    "X_2 = np.array(train2.drop('class', axis=1))\n",
    "y_2 = np.array(train2['class'].cat.codes) #unsigned integers specifying group\n",
    "y_2_cat = np.array(train2['class'])\n",
    "\n",
    "X_test = np.array(test.drop('class', axis=1))\n",
    "y_test = np.array(test['class'].cat.codes)\n",
    "y_test_cat = np.array(test['class'])\n",
    "# print(X_2.shape)\n",
    "# print(y_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train.iloc[:,-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check how many samples per class we have, in order to see if the classes are balanced or not.\n",
    "<a id='fig2.1'></a>\n",
    "#### Fig. 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('class').size().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes are slightly unbalanced, however this unbalance does not seem so important so it shouldn't be a concern for our classification purposes.\n",
    "<a id='fig2.2'></a>\n",
    "#### Fig. 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x=\"class\", y=\"SOD1_N\", data=train, palette=\"Pastel1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we check the distribution of a protein in the different classes. In this case we chose SOD1 because it's the missing protein in our test data. This protein expression varies a lot especially between CS and SC classes. However visualizing all the 77 features like this is unfeasible so we opted for a parallel coordinates plot.\n",
    "<a id='fig2.3'></a>\n",
    "#### Fig. 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# In case you would want to order it\n",
    "\n",
    "# order = train_mean.mean().sort_values()\n",
    "# order = order.index.tolist()\n",
    "# order.append(\"class\")\n",
    "# train_mean = train_mean[order]\n",
    "# train = train[order]\n",
    "\n",
    "# Perform parallel coordinate plot\n",
    "#15,10\n",
    "fig, (ax1,ax2) = plt.subplots(2, figsize=(15,15))\n",
    "plt.grid(b=None)\n",
    "parallel_coordinates(train, 'class',colormap=plt.get_cmap(\"Set1\"), ax=ax1)\n",
    "ax1.set_xticks([])\n",
    "handles, labels = ax1.get_legend_handles_labels()\n",
    "labels\n",
    "ax1.set_title('Parallel coordinates plot')\n",
    "ax1.set_ylabel('Exp')\n",
    "train_mean_class = train.groupby('class').mean()\n",
    "train_mean_class = train_mean_class.reindex(labels)\n",
    "train_mean_class = train_mean_class.reset_index()\n",
    "\n",
    "ax2.set_title('Parallel coordinates plot of the means')\n",
    "ax1.set_ylabel('Mean Exp')\n",
    "\n",
    "parallel_coordinates(train_mean_class, 'class',\n",
    "                     colormap=plt.get_cmap(\"Set1\"), ax=ax2)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this plot we can see the different behaviour of the proteins in the different classes. Some proteins vary a lot and some are quite stable. Also there is a big difference in the values of expression between proteins. This may suggest that some sort of normalization may be needed in succesive analysis. However this plot is not perfectly clear so we opted for a more interpretable dotplot.\n",
    "<a id='fig2.4'></a>\n",
    "#### Fig. 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_mean = train.mean() \n",
    "train_mean.sort_values(inplace=True)\n",
    "\n",
    "train_mean_class = train.groupby('class').mean()\n",
    "train_mean_class = train_mean_class.T\n",
    "train_mean_class = train_mean_class.reindex(index=train_mean.index)\n",
    "\n",
    "train_std = train.std()\n",
    "train_std.sort_values(inplace=True)\n",
    "\n",
    "train_std_class = train.groupby('class').std()\n",
    "train_std_class = train_std_class.T\n",
    "train_std_class = train_std_class.reindex(index=train_std.index)\n",
    "\n",
    "train_std=train_std.reindex(index=train_mean_class.index)\n",
    "train_std_class = train_std_class.reindex(index=train_std.index)\n",
    "\n",
    "# Draw plot\n",
    "\n",
    "fig, (ax1,ax2,ax3,ax4) = plt.subplots(ncols=4, figsize=(15,15))\n",
    "\n",
    "ax1.hlines(y=train_mean.index, xmin = 0,xmax = 5.1,color='gray', alpha=0.7, linewidth=1, linestyles='dashdot')\n",
    "ax1.scatter(y=train_mean.index, x=train_mean.values, s=65,c=train_mean.values, cmap='Reds', alpha=0.7)\n",
    "\n",
    "# Title, Label, Ticks and Ylim\n",
    "ax1.set_title('Dot Plot for Protein Mean', fontdict={'size':14})\n",
    "ax1.set_xlabel('Mean')\n",
    "ax1.tick_params(axis='y', which='major', labelsize=9)\n",
    "ax2.hlines(y=train_mean_class.index, xmin = 0,xmax = 5.1,color='gray', alpha=0.5, linewidth=1, linestyles='dashdot')\n",
    "for idx, val in enumerate(list(train_mean_class.columns)):\n",
    "    ax2.scatter(y=train_mean_class.index, x=train_mean_class.values[:,idx], s=40, alpha=0.7, label  = val)\n",
    "#lgnd = ax2.legend( bbox_to_anchor=(0.9,0.25))\n",
    "#for handle in lgnd.legendHandles:\n",
    "#    handle.set_sizes([50])\n",
    "ax2.set_title('Protein Mean divided by class', fontdict={'size':14})\n",
    "ax2.set_xlabel('Mean')\n",
    "ax2.set_yticks([])\n",
    "\n",
    "ax3.hlines(y=train_std.index, xmin = 0,xmax = 1.65,color='gray', alpha=0.7, linewidth=1, linestyles='dashdot')\n",
    "ax3.scatter(y=train_std.index, x=train_std.values, s=65,c=train_std.values, cmap='Reds', alpha=0.7)\n",
    "\n",
    "# Title, Label, Ticks and Ylim\n",
    "ax3.set_title('Dot Plot for Protein Sd', fontdict={'size':14})\n",
    "ax3.set_xlabel('Sd')\n",
    "ax3.set_yticks([])\n",
    "ax3.tick_params(axis='y', which='major', labelsize=9)\n",
    "\n",
    "ax4.hlines(y=train_std_class.index, xmin = 0,xmax = 1.65,color='gray', alpha=0.5, linewidth=1, linestyles='dashdot')\n",
    "for idx, val in enumerate(list(train_std_class.columns)):\n",
    "    ax4.scatter(y=train_std_class.index, x=train_std_class.values[:,idx], s=40, alpha=0.7, label  = val)\n",
    "lgnd = ax4.legend( bbox_to_anchor=(0.9,0.25))\n",
    "for handle in lgnd.legendHandles:\n",
    "    handle.set_sizes([50])\n",
    "ax4.annotate('SOD1 is an\\nimportant protein!',\n",
    "            color=\"firebrick\",\n",
    "            xy=(0.36, 47), xycoords='data',\n",
    "            xytext=(30, -30), textcoords='offset points',\n",
    "            arrowprops=dict(arrowstyle=\"->\"))\n",
    "ax4.set_title('Protein Sd divided by class', fontdict={'size':14})\n",
    "ax4.set_xlabel('Sd')\n",
    "ax4.set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this plot we can see the mean and the standard deviation of all the proteins in the 8 different classes. Many proteins have low mean expression value with low variation between classes, however the supposedly informative proteins (essentially the ones with great variation) are quite easily recognizable. It also shows that the expressionn values are on quite different ranges with most of the proteins between 0-1 and few between 1-5, this suggests that we should normalize our data before the clustering. SOD1 appears to be a very important protein, it varies much more than the majority of proteins with similar expression values especially between CS and SC classes as seen in [(vd Fig 2.2.)](#fig2.2)\n",
    "\n",
    "Then we explored correlation between all features to explore if there were some evident patterns and to check if multicollinearity may be a problem.\n",
    "<a id='fig2.5'></a>\n",
    "#### Fig.2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap for feature correlation\n",
    "X_df = train.drop('class', axis=1)\n",
    "corr_df = X_df.corr()\n",
    "#sns.heatmap(corr_df)\n",
    "fig, ax = plt.subplots(figsize=(17,17)) \n",
    "\n",
    "cax = ax.matshow(corr_df,cmap='RdYlGn_r', vmin=-1, vmax=1)\n",
    "fig.colorbar(cax,fraction=0.046, pad=0.04)\n",
    "ticks = np.arange(0,len(X_df.columns),1)\n",
    "ax.set_xticks(ticks)\n",
    "plt.xticks(rotation=90)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(X_df.columns)\n",
    "ax.set_yticklabels(X_df.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are few correlated features, mostly positively especially DYRK1A, NR1, NR2A, pELK, pERK, ELK, ERK. SOD1 seems negatively correlated with few proteins. Sorting the matrix by the mean expression value may be a good idea.\n",
    "<a id='fig2.6'></a>\n",
    "#### Fig. 2.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df_ordered = corr_df.reindex(index = train_mean.index)\n",
    "corr_df_ordered = corr_df_ordered[list(train_mean.index)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(17,17)) \n",
    "\n",
    "cax = ax.matshow(corr_df_ordered,cmap='RdYlGn_r', vmin=-1, vmax=1)\n",
    "fig.colorbar(cax,fraction=0.046, pad=0.04)\n",
    "ticks = np.arange(0,len(corr_df_ordered.columns),1)\n",
    "ax.set_xticks(ticks)\n",
    "plt.xticks(rotation=90)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(corr_df_ordered.columns)\n",
    "ax.set_yticklabels(corr_df_ordered.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This figure shows how proteins with high expression values (lower rows and right columns) tend to be higly correlated with each other. Whereas proteins with lower expression (higher rows and left columns) tend to be uncorrelated except BAX and NUMB. \n",
    "<a id='fig2.7'></a>\n",
    "#### Fig. 2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TC = train[list(train_mean.index)+['class']].groupby('class')\n",
    "\n",
    "corr_classes=TC.corr()\n",
    "\n",
    "fig,axn = plt.subplots(2, 4, sharex=True, sharey=True, figsize=(20, 10))#fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "cbar_ax = fig.add_axes([.92, 0.13, .03, .75])\n",
    "\n",
    "i=1\n",
    "for a,b in TC:\n",
    "    ax = plt.subplot(2, 4, i)\n",
    "    if i == 8:\n",
    "        sns.heatmap(corr_classes.loc[a], cmap='RdYlGn_r',vmin=-1, vmax=1,cbar=True,cbar_ax = cbar_ax,  \n",
    "                    xticklabels=False, yticklabels=False, ax=ax)\n",
    "    else:\n",
    "        sns.heatmap(corr_classes.loc[a], cmap='RdYlGn_r',vmin=-1, vmax=1,cbar=False, xticklabels=False, \n",
    "                    yticklabels=False, ax=ax)\n",
    "    ax.set_title(a, fontdict={'size':10})\n",
    "    i=i+1\n",
    "        #plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the correlation  patterns is quite consistent between the classes. It appears 'weaker' in t-SC-m and 'stronger' in t-SC-s.\n",
    "\n",
    "<a id='tab2.1'></a>\n",
    "#### Tab 2.1"
   ]
  },
  {
   "attachments": {
    "comp.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![comp.png](attachment:comp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, as done in the paper, we tried to identify those proteins with significantly different levels between two classes. We used the same approach of the authors. First we decided the meaningful comparisons, shown in [Tab 2.1.](#tab2.1) with their biological interpretation. Then we performed for each protein a Wilcoxon test comparing the values of one class vs another class. This means 77 proteins * 8 comparsions = 616 tests. As a result we obtained a list of proteins which significantly varies between two classes. This may be helpful to validate the clustering but also to focus the attention on a the subset of protein which appear to be discriminant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisons = [['c-CS-s','c-SC-s'], ['c-CS-m','c-SC-m'],['c-SC-m','c-SC-s'],\n",
    "              ['c-CS-m','c-SC-s'],['t-CS-s','t-SC-s'],['t-CS-m','t-SC-m'],\n",
    "              ['t-SC-m','t-SC-s'],['t-CS-m','t-CS-s'],['t-SC-s','c-SC-s']]\n",
    "\n",
    "sig = {}\n",
    "comp = []\n",
    "prot = [] \n",
    "pval = []\n",
    "\n",
    "for idx, val in enumerate(comparisons):\n",
    "    for idx2, val2 in enumerate(train.columns[:-1]):\n",
    "        a = train.loc[train['class'] == val[0]][val2]\n",
    "        b = train.loc[train['class'] == val[1]][val2]\n",
    "        result = stats.mannwhitneyu(a,b)\n",
    "        string = \" vs \".join(val)\n",
    "        comp.append(string)\n",
    "        prot.append(val2)\n",
    "        pval.append(result.pvalue)\n",
    "        sig['test'] = comp\n",
    "        sig['protein'] = prot\n",
    "        sig['result'] = pval\n",
    "#         sig.append([val,val2,result.pvalue])\n",
    "# sig[0].append(['ciao','bye'])    \n",
    "wilc = pd.DataFrame(sig)\n",
    "#wilc.loc[wilc[protein] == 'DYRK1A_N']\n",
    "wilc = wilc.pivot_table(index = 'protein',\n",
    "               columns = 'test',\n",
    "               values = 'result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wilc_correct = wilc.copy()\n",
    "sig_dict = {}\n",
    "\n",
    "for idx, val in enumerate (wilc_correct.columns):\n",
    "    arr = multi.multipletests(wilc.loc[:,val], method='bonferroni')[1]\n",
    "    # p val * 77\n",
    "    col = [t for t in arr]\n",
    "    wilc_correct.loc[:,val] = col\n",
    "    sig_dict[val] = list(wilc_correct.loc[wilc_correct[val] < 0.05].index)\n",
    "\n",
    "print(sig_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now sig_dict contains all the comparisons as keys and the significant proteins as values. It is important to note that the p-values were adjusted with the Bonferroni correction, the most conservative one.\n",
    "\n",
    "This is some code to create dataframes and functions that we'll need later. Essentialy these are the dataset that we'll use perform the clustering algorithms or PCA. We also created dataset with reduced features for both only controls and only trisomic samples. The features were selected by computing the union of the sets of proteins that were previously found significant. This is done to see if the discriminant proteins are actually critical to class discrimination. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(train.drop('class', axis=1)) #the floating point values\n",
    "y = np.array(train['class'].cat.codes) #unsigned integers specifying group\n",
    "y_cat = np.array(train['class'])\n",
    "\n",
    "X_mm = MinMaxScaler().fit_transform(X)\n",
    "X_std = StandardScaler().fit_transform(X)\n",
    "\n",
    "label_dict = { np.unique(y)[k] : np.unique(y_cat)[k] for k in range(len(np.unique(y_cat)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "comp_c = ['c-CS-m vs c-SC-m','c-CS-m vs c-SC-s','c-CS-s vs c-SC-s','c-SC-m vs c-SC-s']\n",
    "comp_t = ['t-CS-m vs t-CS-s','t-CS-m vs t-SC-m', 't-CS-s vs t-SC-s', 't-SC-m vs t-SC-s']\n",
    "union_c = list(set(sig_dict[comp_c[0]]) | set(sig_dict[comp_c[1]]) | set(sig_dict[comp_c[2]]) | set(sig_dict[comp_c[3]]))\n",
    "union_t = list(set(sig_dict[comp_t[0]]) | set(sig_dict[comp_t[1]]) | set(sig_dict[comp_t[2]]) | set(sig_dict[comp_t[3]]))\n",
    "\n",
    "full_train_c = full_train[full_train.status==0]\n",
    "\n",
    "df_c_red = full_train_c[union_c]\n",
    "df_c = full_train_c[train.drop('class', axis=1).columns]\n",
    "\n",
    "full_train_t = full_train[full_train.status==1]\n",
    "df_t_red = full_train_t[union_t]\n",
    "df_t = full_train_t[train.drop('class', axis=1).columns]\n",
    "\n",
    "X_c = MinMaxScaler().fit_transform(np.array(df_c)) #the floating point values\n",
    "y_c = np.array(full_train_c['class'].cat.codes) #unsigned integers specifying group\n",
    "#plot_pca3d(X_c, y_c)\n",
    "y_c_cat = np.array(full_train_c['class'])\n",
    "label_dict_c = { np.unique(y_c)[k] : np.unique(y_c_cat)[k] for k in range(len(np.unique(y_c_cat)))}\n",
    "\n",
    "X_t = MinMaxScaler().fit_transform(np.array(df_t)) #the floating point values\n",
    "y_t = np.array(full_train_t['class'].cat.codes) #unsigned integers specifying group\n",
    "#plot_pca3d(X_c, y_c)\n",
    "y_t_cat = np.array(full_train_t['class'])\n",
    "label_dict_t = { np.unique(y_t)[k] : np.unique(y_t_cat)[k] for k in range(len(np.unique(y_t_cat)))}\n",
    "\n",
    "X_c_red = MinMaxScaler().fit_transform(np.array(df_c_red)) #the floating point values\n",
    "X_t_red = MinMaxScaler().fit_transform(np.array(df_t_red)) #the floating point values\n",
    "\n",
    "full_train_CS = full_train[full_train.learn_stim==1]\n",
    "df_CS = full_train_CS[train.drop('class', axis=1).columns]\n",
    "X_CS = MinMaxScaler().fit_transform(np.array(df_CS))\n",
    "y_CS = np.array(full_train_CS['class'].cat.codes) #unsigned integers specifying group\n",
    "#plot_pca3d(X_c, y_c)\n",
    "y_CS_cat = np.array(full_train_CS['class'])\n",
    "label_dict_CS = { np.unique(y_CS)[k] : np.unique(y_CS_cat)[k] for k in range(len(np.unique(y_CS_cat)))}\n",
    "\n",
    "\n",
    "full_train_SC = full_train[full_train.learn_stim==0]\n",
    "df_SC = full_train_SC[train.drop('class', axis=1).columns]\n",
    "X_SC = MinMaxScaler().fit_transform(np.array(df_SC))\n",
    "y_SC = np.array(full_train_SC['class'].cat.codes) #unsigned integers specifying group\n",
    "#plot_pca3d(X_c, y_c)\n",
    "y_SC_cat = np.array(full_train_SC['class'])\n",
    "label_dict_SC = { np.unique(y_SC)[k] : np.unique(y_SC_cat)[k] for k in range(len(np.unique(y_SC_cat)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_varexp(X, title):\n",
    "    pca = PCA().fit(X)\n",
    "    fig = plt.figure(figsize=(8,5))\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "    plt.xlabel('number of components')\n",
    "    plt.ylabel('cumulative explained variance')\n",
    "    plt.title(title)\n",
    "    major_ticks = np.arange(0, X.shape[1], 10)\n",
    "    minor_ticks = np.arange(0, X.shape[1], 1)\n",
    "    ax.set_xticks(major_ticks)\n",
    "    ax.set_ylim([0,1])\n",
    "    ax.set_xticks(minor_ticks, minor=True)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_pca2d(X, y_cat,title):\n",
    "    pca2 = PCA(n_components=2)  # project from 76 to 2 dimensions\n",
    "    projected2 = pca2.fit_transform(X)\n",
    "\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    sns.scatterplot(projected2[:, 0], projected2[:, 1], hue=y_cat, edgecolor='k',\n",
    "                    palette=sns.color_palette(\"Set2\", n_colors=np.unique(y_cat).shape[0]))\n",
    "    plt.xlabel('PC 1 (%.2f%%)' % (pca2.explained_variance_ratio_[0]*100))\n",
    "    plt.ylabel('PC 2 (%.2f%%)' % (pca2.explained_variance_ratio_[1]*100))\n",
    "    plt.title(title)\n",
    "    plt.show()    \n",
    "\n",
    "def plot_pca3d(X, y, df,title):\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "    fig = plt.figure(figsize=(10, 10), dpi=96)\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    pca = PCA(n_components=3)\n",
    "    pca.fit(X)\n",
    "    X_trans = pca.transform(X)\n",
    "\n",
    "    labelTups = list(zip(list(y),list(df['class'])))\n",
    "    labelTups = list(set(labelTups))\n",
    "    label_dict = {item[0]: item[1] for item in labelTups}\n",
    "\n",
    "    sc = ax.scatter(X_trans[:, 0], X_trans[:, 1], X_trans[:, 2], c=y, \n",
    "                    cmap=plt.cm.get_cmap(\"Set2\"), edgecolor='k', s=130)\n",
    "\n",
    "    result=pd.DataFrame(X_trans, columns=['PCA%i' % i for i in range(3)], \n",
    "                        index=df.index)\n",
    "\n",
    "    colors = [sc.cmap(sc.norm(i)) for i in [t[0] for t in labelTups]]\n",
    "    custom_lines = [plt.Line2D([],[], ls=\"\", marker='.', \n",
    "                    mec='k', mfc=c, mew=.1, ms=20) for c in colors]\n",
    "    ax.legend(custom_lines, [lt[1] for lt in labelTups], \n",
    "              loc='center left', bbox_to_anchor=(1.0, .5))\n",
    "\n",
    "    xAxisLine = ((min(result['PCA0']), max(result['PCA0'])), (0, 0), (0,0))\n",
    "    ax.plot(xAxisLine[0], xAxisLine[1], xAxisLine[2], 'r')\n",
    "    yAxisLine = ((0, 0), (min(result['PCA1']), max(result['PCA1'])), (0,0))\n",
    "    ax.plot(yAxisLine[0], yAxisLine[1], yAxisLine[2], 'r')\n",
    "    zAxisLine = ((0, 0), (0,0), (min(result['PCA2']), max(result['PCA2'])))\n",
    "    ax.plot(zAxisLine[0], zAxisLine[1], zAxisLine[2], 'r')\n",
    "\n",
    "    # ax.text(x=0.74048959,y=-1.85937686,z=1.64074746,s= 'ciao')\n",
    "    #  to check if correct color-legend assignment\n",
    "    # label the axes\n",
    "    ax.set_xlabel('PC 1 (%.2f%%)' % (pca.explained_variance_ratio_[0]*100))\n",
    "    ax.set_ylabel('PC 2 (%.2f%%)' % (pca.explained_variance_ratio_[1]*100))\n",
    "    ax.set_zlabel('PC 3 (%.2f%%)' % (pca.explained_variance_ratio_[2]*100))\n",
    "    ax.set_title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We performed PCA to check how much variance is explained by the principal components. We did this on the original data, on Min-Max scaled data and on the standardized data. Prior to PCA it's important to normalize especially when there are features measured with different scales. This is done to avoid giving too much importance to variables that have higher variance only because of their specific scale. Even though all the features here are measured in the same assay with the same units normalizing may still be a good idea given that the ranges of protein expression are so different. The authors of the paper opted for min-max scaling, which basically 'shrink' all your estimates in the interval 0,1. Here, the original data were also standardized, which means centering the mean at 0 and fixing the variance at 1. \n",
    "\n",
    "<a id='fig2.8'></a>\n",
    "#### Fig. 2.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_varexp(X, \"PCA\")\n",
    "pca_varexp(X_mm, \"PCA on scaled values (minmax)\")\n",
    "pca_varexp(X_std, \"PCA on standardized values (standardized)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that for the PCA on raw data the first few components explain most of the variability of the data. This is due to the fact that without normalization proteins with higher expression values, and with higher variance, will have more importance than the other features in lower ranges. This causes the 1st PC to explain 35 % of the variance, all the samples would be stretched along this main axis. \n",
    "\n",
    "Normalizing the data avoids this phenomenon and we can see that the proportion of variance explained increase much more slowly. The two different normalizations seem to behave in a similar manner.\n",
    "\n",
    "The subsequent analyses were performed on Min-Max scaled data because they produced good results and to keep reproducibility with the paper (even though how you standardize your data should not cause any significant difference).\n",
    "\n",
    "<a id='fig2.9'></a>\n",
    "#### Fig. 2.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pca2d(X, y_cat, \"PCA\")\n",
    "plot_pca3d(X, y, train, \"PCA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that not normalized data stretch along the main axis and they don't appear to be clearly clustered.\n",
    "\n",
    "<a id='fig2.10'></a>\n",
    "#### Fig. 2.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pca2d(X_mm, y_cat, \"PCA\")\n",
    "plot_pca3d(X_mm, y, train, \"PCA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the variance explained by the first 3 axis is much less, the minmax scaled data appear to be clustered in two main groups divided along the 2nd axis. These groups are mainly represened by the SC and CS samples. This plot can be made interactive if %matplotlib notebook is added in the script (it does not always work however).\n",
    "\n",
    "As done in the paper these analyses were also performed on only control samples and only trisomic samples.\n",
    "<a id='fig2.11'></a>\n",
    "#### Fig. 2.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%matplotlib notebook \n",
    "#-> make it interactive\n",
    "#%matplotlib inline \n",
    "#-> make it static\n",
    "\n",
    "plot_pca2d(X_c, y_c_cat,\"PCA on only control samples\")\n",
    "plot_pca2d(X_c_red, y_c_cat,\"PCA on only control samples on selected features n=23\")\n",
    "plot_pca3d(X_c,y_c,full_train_c,\"PCA on control cases\")\n",
    "plot_pca3d(X_c_red,y_c,full_train_c, \"PCA on control cases and selected features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The control samples seems to be clearly spearated between those who learn (CS) and those who doesn't (SC). This confirms the paper findings that learning in controls seems to be associated with a different level of expression. \n",
    "<a id='fig2.12'></a>\n",
    "#### Fig. 2.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_pca2d(X_t, y_t_cat,\"PCA on only trisomic samples\")\n",
    "plot_pca3d(X_t,y_t,full_train_t, \"PCA on trisomic cases\")\n",
    "plot_pca2d(X_t_red, y_t_cat,\"PCA on only trisomic samples on selected features n=23\")\n",
    "plot_pca3d(X_t_red,y_t,full_train_t, title=\"PCA on trisomic cases and selected features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trisomic samples show more or less the same behaviour. The CS and SC classes are clearly separated. In this case the most interesting class is t-CS-s because they fail to learn. Supposedly, given the seemingly importance of learning, they should be closer to SC samples. This tendency however it's not clearly observed here. It can be argued that the main factor may not be learning but fear. \\\n",
    "The same can be done for exclusively SC and CS classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_pca2d(X_CS, y_CS_cat, \"PCA on CS\")\n",
    "plot_pca3d(X_CS, y_CS, full_train_CS,\"PCA on CS\")\n",
    "plot_pca2d(X_SC, y_SC_cat, \"PCA on SC\")\n",
    "plot_pca3d(X_SC, y_SC, full_train_SC,\"PCA on SC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the groupings are not so defined, we have seen that the differences are mainly between SC and CS and not within.\n",
    "<a id='section_3'></a>\n",
    "# 3. Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering is generally used to find important structures or analyze groupings in the data. This could help us discover features and properties that characterize the dataset and the different groups. Usually, clustering is an unsupervised machine learning method, which means that the input data do not have an associated label. However, in our case, the data are labelled so, it will be much easier to assess the quality of the results of a clustering algorithm. In fact, we can use the label information to check if the cluster are homogenous and in agreement with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section_3.1'></a>\n",
    "### Agglomerative hierarchical clustering\n",
    "\n",
    "Agglomerative hierarchical clustering is a clustering algorithm that builds clusters by merging groups succesively based on a distance measure. This process is reiterated until all clusters have been merged into one unique cluster. For this reason, this approach is also called bottom-up. The hierarchy of clusters is represented by a tree. The root is the unique big cluster and the tips are the single samples.\n",
    "\n",
    "Intuitively, the hierachical clustering perfomance should be pretty accurate as the different classes are somehow hierarchically related among each others. Indeed, the classes are characterized by different combinations of syndrome, stimulation and injection. It will be expected that this structure will emerge in the hierarchical clustering.\n",
    "\n",
    "These are some functions that will help us visualize and evaluate the quality of the final clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dendrogram(Z=None, model=None, X=None, **kwargs):\n",
    "    annotate_above = kwargs.pop('annotate_above', 0)\n",
    "\n",
    "    # Reconstruct the linakge matrix if the standard model API was used\n",
    "    if Z is None:\n",
    "        if hasattr(model, 'distances_') and model.distances_ is not None:\n",
    "            # create the counts of samples under each node\n",
    "            counts = np.zeros(model.children_.shape[0])\n",
    "            n_samples = len(model.labels_)\n",
    "            for i, merge in enumerate(model.children_):\n",
    "                current_count = 0\n",
    "                for child_idx in merge:\n",
    "                    if child_idx < n_samples:\n",
    "                        current_count += 1  # leaf node\n",
    "                    else:\n",
    "                        current_count += counts[child_idx - n_samples]\n",
    "                counts[i] = current_count\n",
    "\n",
    "            Z = np.column_stack([model.children_, model.distances_,\n",
    "                                              counts]).astype(float)\n",
    "        else:\n",
    "            Z = linkage(X, method=model.linkage, metric=model.affinity)\n",
    "    \n",
    "    if 'n_clusters' in kwargs:\n",
    "        n_clusters = kwargs.pop('n_clusters')\n",
    "        # Set the cut point just above the last but 'n_clusters' merge\n",
    "        kwargs['color_threshold'] = Z[-n_clusters, 2] + 1e-6\n",
    "    \n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    # Plot the corresponding dendrogram\n",
    "    ddata = dendrogram(Z, ax=ax, **kwargs) \n",
    "    \n",
    "    # Annotate nodes in the dendrogram\n",
    "    for i, d, c in zip(ddata['icoord'], ddata['dcoord'], ddata['color_list']):\n",
    "        x = 0.5 * sum(i[1:3])\n",
    "        y = d[1]\n",
    "        nid = np.where(Z[:,2] == y)[0][0]\n",
    "        if y > annotate_above:\n",
    "            plt.plot(x, y, 'o', c=c)\n",
    "            plt.annotate(str(nid-Z.shape[0]), (x, y), xytext=(0, -5),\n",
    "                         textcoords='offset points',\n",
    "                         va='top', ha='center')\n",
    "    if kwargs['color_threshold']:\n",
    "        plt.axhline(y=kwargs['color_threshold'], c='k')\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "def get_node_leaves(Z, idx, N):\n",
    "    n1, n2 = Z[idx,0], Z[idx,1]\n",
    "    leaves = []\n",
    "    for n in [n1, n2]:\n",
    "        leaves += [int(n)] if n < N else get_node_leaves(Z, int(n-N), N)\n",
    "    return leaves\n",
    "\n",
    "def get_node(Z, X, y, idx, dic):\n",
    "    title = str(idx)\n",
    "    leaves = get_node_leaves(Z, idx, X.shape[0])\n",
    "    labels, counts = np.unique(y[leaves], return_counts=True)\n",
    "    labels_cat = [dic[i] for i in labels]\n",
    "    count_abs = np.unique(y, return_counts=True)\n",
    "    nleaves = len(leaves)\n",
    "    freq = []\n",
    "    for idx, val in enumerate(counts):\n",
    "        index = np.where(labels[idx]==count_abs[0])\n",
    "        fr = val/count_abs[1][index]\n",
    "        freq.append(float(fr))\n",
    "    freq = np.array(freq)\n",
    "#   print(np.concatenate(np.array(counts).reshape(1,-1), freq))\n",
    "    print(pd.DataFrame([counts,freq], \n",
    "                       columns=labels_cat, index=[\"Count:\",\"Frequency:\"]))\n",
    "    print(\"Samples in the cluster:\", len(leaves), \"/\", X.shape[0])\n",
    "    y_pos = np.arange(len(labels_cat))\n",
    "    plt.bar(y_pos, counts)\n",
    "    plt.ylim(0,50)\n",
    "    plt.title(title)\n",
    "    plt.xticks(y_pos, labels_cat)\n",
    "    plt.show()\n",
    "\n",
    "def plot_clust_2d(X, y_cat, y_predict,title):\n",
    "    pca2 = PCA(n_components=2)  # project from 76 to 2 dimensions\n",
    "    projected2 = pca2.fit_transform(X)    \n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    \n",
    "    sns.scatterplot(projected2[:, 0], projected2[:, 1], hue=y_cat, edgecolor='k', style=y_predict,\n",
    "                    palette=sns.color_palette(\"Set2\", n_colors=np.unique(y_cat).shape[0]))\n",
    "    plt.xlabel('PC 1 (%.2f%%)' % (pca2.explained_variance_ratio_[0]*100))\n",
    "    plt.ylabel('PC 2 (%.2f%%)' % (pca2.explained_variance_ratio_[1]*100))\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_clust_3d(X, y, df, y_predict, title):\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 10), dpi=96)\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    used = set()\n",
    "    uniq = [x for x in y if x not in used and (used.add(x) or True)]\n",
    "    colors = sns.color_palette(\"Set2\", n_colors=8).as_hex()\n",
    "    col_legend = [colors[i] for i in uniq]\n",
    "    markers = [\".\",\"v\",\"s\",\"*\", \"X\",\"p\",\"d\",\"^\"]\n",
    "    \n",
    "    pca = PCA(n_components=3)\n",
    "    pca.fit(X)\n",
    "    X_trans = pca.transform(X)\n",
    "    \n",
    "    used2 = set()\n",
    "    labelTups = list(zip(list(y),list(df['class'])))\n",
    "    labelTups = [x for x in labelTups if x not in used2 and (used2.add(x) or True)]\n",
    "    #labelTups = list(set(labelTups))\n",
    "    #label_dict = {item[0]: item[1] for item in labelTups}\n",
    "\n",
    "    for i in range(len(X_trans)):\n",
    "        ax.scatter(X_trans[i, 0], X_trans[i, 1], X_trans[i, 2], c=colors[y[i]],\n",
    "                   marker=markers[y_predict[i]],\n",
    "                   edgecolor='k', s=130)\n",
    "\n",
    "\n",
    "    result=pd.DataFrame(X_trans, columns=['PCA%i' % i for i in range(3)], \n",
    "                        index=df.index)\n",
    "\n",
    "    custom_lines = [plt.Line2D([],[], ls=\"\", marker='.', \n",
    "                    mec='k', mfc=c, mew=.1, ms=20) for c in col_legend]\n",
    "    ax.legend(custom_lines, [lt[1] for lt in labelTups], \n",
    "              loc='center left', bbox_to_anchor=(1.0, .5))\n",
    "\n",
    "    xAxisLine = ((min(result['PCA0']), max(result['PCA0'])), (0, 0), (0,0))\n",
    "    ax.plot(xAxisLine[0], xAxisLine[1], xAxisLine[2], 'r')\n",
    "    yAxisLine = ((0, 0), (min(result['PCA1']), max(result['PCA1'])), (0,0))\n",
    "    ax.plot(yAxisLine[0], yAxisLine[1], yAxisLine[2], 'r')\n",
    "    zAxisLine = ((0, 0), (0,0), (min(result['PCA2']), max(result['PCA2'])))\n",
    "    ax.plot(zAxisLine[0], zAxisLine[1], zAxisLine[2], 'r')\n",
    "\n",
    "    # ax.text(x=0.74048959,y=-1.85937686,z=1.64074746,s= 'ciao')\n",
    "    #  to check if correct color-legend assignment\n",
    "    # label the axes\n",
    "    ax.set_xlabel('PC 1 (%.2f%%)' % (pca.explained_variance_ratio_[0]*100))\n",
    "    ax.set_ylabel('PC 2 (%.2f%%)' % (pca.explained_variance_ratio_[1]*100))\n",
    "    ax.set_zlabel('PC 3 (%.2f%%)' % (pca.explained_variance_ratio_[2]*100))\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_cm(labels_true, labels_pred, labels_dict):\n",
    "    cm = contingency_matrix( labels_true = labels_true, labels_pred = labels_pred)\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    plt.imshow(cm,interpolation='none',cmap='summer_r')\n",
    "    for (i, j), z in np.ndenumerate(cm):\n",
    "        plt.text(j, i, z, ha='center', va='center')\n",
    "    ax.set_yticks(range(len(list(labels_dict.keys()))))\n",
    "    ax.set_yticklabels(list(labels_dict.values()))\n",
    "    plt.xlabel(\"hclust label\")\n",
    "    plt.ylabel(\"truth label\")\n",
    "    plt.show()\n",
    "\n",
    "def incidence_mat(y_pred):\n",
    "    npoints = y_pred.shape[0]\n",
    "    mat = np.zeros([npoints, npoints])\n",
    "    # Retrieve how many different cluster ids there are\n",
    "    clusters = np.unique(y_pred)\n",
    "    nclusters = clusters.shape[0]\n",
    "    \n",
    "    for i in range(nclusters):\n",
    "        sample_idx = np.where(y_pred == i)\n",
    "        # Compute combinations of these indices\n",
    "        idx = np.meshgrid(sample_idx, sample_idx)\n",
    "        mat[idx[0].reshape(-1), idx[1].reshape(-1)] = 1\n",
    "        \n",
    "    return mat\n",
    "\n",
    "def similarity_mat(X, metric):\n",
    "    dist_mat = pairwise_distances(X, metric=metric)\n",
    "    min_dist, max_dist = dist_mat.min(), dist_mat.max()\n",
    "    sim_mat = 1 - (dist_mat - min_dist) / (max_dist - min_dist)\n",
    "    return sim_mat\n",
    "\n",
    "def correlation(X, y_pred, metric):\n",
    "    inc = incidence_mat(y_pred)\n",
    "    sim = similarity_mat(X, metric)\n",
    "    \n",
    "    # Note: we can eventually remove duplicate values\n",
    "    # only the upper/lower triangular matrix\n",
    "    # triuidx = np.triu_indices(y_pred.shape[0], k=1)\n",
    "    # inc = inc[triuidx]\n",
    "    # sim = sim[triuidx]\n",
    "    \n",
    "    inc = normalize(inc.reshape(1, -1))\n",
    "    sim = normalize(sim.reshape(1, -1))\n",
    "    corr = (inc @ sim.T)\n",
    "    return corr[0,0]   \n",
    "\n",
    "def sorted_sim(sim, y_pred):\n",
    "    idx_sorted = np.argsort(y_pred)\n",
    "    # Sort the rows\n",
    "    sim = sim[idx_sorted]\n",
    "    # Sort the columns\n",
    "    sim = sim[:, idx_sorted]\n",
    "    \n",
    "    return sim\n",
    "\n",
    "def plot_sorted_sim(sim, y_pred):\n",
    "    sim = sorted_sim(sim, y_pred)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12,8))  \n",
    "    ax = sns.heatmap(sim, ax=ax,cmap='RdYlGn_r')\n",
    "    # Remove ruler (ticks)\n",
    "    ax.set_yticks([]) \n",
    "    ax.set_xticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agglomerative hierarchical clustering performance depends on two decisions. One is the metric used to define distances between two data points. The other is the linkage criteria. This determines the way the clusters are merged together. There are 5 basic alternatives:\n",
    "\n",
    "1. **Single** linkage minimizes distance between closest observations of pairs of clusters\n",
    "2. **Average** linkage minimizes the average of distances between observations of pairs of clusters \n",
    "3. **Maximum** linkage minimizes the maximum distance between observations of pairs of clusters\n",
    "4. **Centroid** linkage minimizes the distance between centroids of pairs of clusters\n",
    "5. **Ward** linkage minimizes the total within-cluster variance\n",
    "\n",
    "Each linkage has different properties and its efficacy depends on the data. Single linkage is very efficient and can handle non-elliptical shapes but is quite sensitive to noise and outliers. Whereas complete linkage is more robust to noise but it's biased to globular shapes. Centroid linkage may suffer inversions. Ward is generally very stable.\n",
    "\n",
    "Here, all 5 linkage methods are tested on the data to understand which one might work better. Note that the euclidean distance is used. We assume that with other metrics the result would be comparable.\n",
    "\n",
    "<a id='fig3.1'></a>\n",
    "#### Fig. 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "methods = ['single', 'average', 'complete', 'centroid', 'ward']\n",
    "\n",
    "for method in methods:\n",
    "    Z = linkage(X_mm, metric='euclidean', method=method)\n",
    "    fig, ax = plot_dendrogram(Z=Z, X=X_mm, truncate_mode='lastp', \n",
    "                              p=100, n_clusters=10)\n",
    "    ax.set_title(method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Single** linkage is the one that provides smaller jumps among all. The dendrogram produce is not good at all in our case\n",
    "- **Average** linkage as single linkage has very little jumps between clusters\n",
    "- **Complete** linkage seems quite good\n",
    "- **Centroids** linkage dednrogram is similar to the single linkage one and there are some inversions \n",
    "- **Ward** linkage seems like a reasonable dendrogram\n",
    "\n",
    "From now on we decide to use Ward linkage method because it seems to produce the best dendrogram. For this reason we also use Euclidean distance which is the only one supported by this method.\n",
    "\n",
    "Now we explore in more detail the chosen denrogram. We can see the distibution of classes in a certain node, using a function defined before, and we can use some tpical clustering metrics.\n",
    "\n",
    "<a id='fig3.2'></a>\n",
    "#### Fig. 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the linkage matrix\n",
    "Z = linkage(X_mm, metric='euclidean', method='ward')\n",
    "plot_dendrogram(Z=Z, X=X_mm,truncate_mode='lastp', \n",
    "                p=50, n_clusters=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_node(Z,X_mm,y, -10, label_dict)\n",
    "get_node(Z,X_mm,y, -8, label_dict)\n",
    "get_node(Z,X_mm,y, -27, label_dict)\n",
    "get_node(Z,X_mm,y, -34, label_dict)\n",
    "get_node(Z,X_mm,y, -9, label_dict)\n",
    "get_node(Z,X_mm,y, -11, label_dict)\n",
    "get_node(Z,X_mm,y, -21, label_dict)\n",
    "get_node(Z,X_mm,y, -12, label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These barplots can help us understand what is the distibution, the frequency and the count of the classes inside a specific node of the tree. \n",
    "\n",
    "Starting from the two biggest clusters (the **bold** ones are the final 8 clusters): \n",
    "- *Cluster -4*: This cluster contains all the CS classes\n",
    "    - **Cluster -10**: same as parent node\n",
    "    - **Cluster -8**: same as parent node with majority of t-CS\n",
    "- *Cluster -2*: This cluster contains all classes but comprise 100% of the SC with 5/137 CS\n",
    "    - *Cluster -5*: contains the majority of SC, only t-SC-s is only 50%\n",
    "        - **Cluster -27** contains only few SC samples with more t than c\n",
    "        - **Cluster -34**: contains few t-SC samples\n",
    "        - **Cluster -9**: contains almost all c-SC samples with half of the t-SC samples and 3 CS exceptions\n",
    "    - *Cluster -3*: contains more than half of the CS classes and 43% of t-CS-m, the other SC classes are only few excpetions\n",
    "        - **Cluster -11**: contains samples from all classes, this cluster is quite noisy\n",
    "        - **Cluster -21**: as before\n",
    "        - **Cluster -12**: this node is represented by mostly cs samples but it's not so homogenous\n",
    "        \n",
    "This clustering is satisfying when analysing the distionction between SC and CS classes. Indeed, these two groups are quite clearly differentiated. Differently, it's hard to spot distinctions among the influence of the injection and the karyotype.\n",
    "\n",
    "Agglomerative hierarchical clustering can also be done using scikit API. \\\n",
    "Using one of the functions previously defined we visually analise the clustering on PCA reduced dimensions, assigning to each point the color based on its true label and the shape based on its predicted one.\n",
    "\n",
    "<a id='fig3.2'></a>\n",
    "#### Fig. 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "distance_threshold=None#270\n",
    "n_clusters=8\n",
    "\n",
    "model = AgglomerativeClustering(n_clusters=n_clusters, \n",
    "                                distance_threshold=distance_threshold, \n",
    "                                affinity='euclidean', linkage='ward')\n",
    "\n",
    "y_predict = model.fit_predict(X_mm)\n",
    "plot_clust_3d(X_mm, y, train,y_predict, \"PCA\")\n",
    "plot_clust_2d(X_mm, y_cat, y_predict, \"PCA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing these plots, it can be noticed that the distinction between the CS and SC clusters can be visually spotted. For instance, in the 2-dimentional plot, the rhombus and the circle almost completely correspond to the CS label, and hence represent clusters 10 and 8.\n",
    "\n",
    "In order to quantitatively evaluate the quality of the clusters and clustering, different measures have been used.\n",
    "\n",
    "1. Using true label information:\n",
    "\n",
    "    **Adjusted random index**\n",
    "\n",
    "    the adjusted Rand index is a function that measures the similarity between the true labels and the predicted ones. Perfect is 1, negative measures are bad and 0 means random label assignments. No assumption is made on the cluster structure.\n",
    "\n",
    "    **V-measure**\n",
    "    \n",
    "    Harmonic mean between homogeneity (each cluster with members of just one class) and completeness (proportional to qunatity of members of class in same cluster). 0 is the worst and 1 is perfect.\n",
    "    \n",
    "    **Fowlkes-Mallows score**\n",
    "    \n",
    "    this index is the geometric mean between the pairwise precision and recall. It ranges from 0 to 1. 1 is perfect.\n",
    "    \n",
    "    **Contingency matrix**\n",
    "    \n",
    "    this matrix represent the intersection between the true labels and the predicted ones. It is an useful way to quickly visualize the efficacy of a clustering algorithm if the classes are few.\n",
    "    \n",
    "\n",
    "2. Properly unsupervised:\n",
    "\n",
    "    **Silhouette**:\n",
    "     in these cases evaluation must be performed using the model itself. A higher Silhouette Coefficient score relates to a model with better defined clusters. The Silhouette Coefficient is defined for each sample and is composed of two scores:\n",
    "    \n",
    "    a: The mean distance between a sample and all other points in the same class.\n",
    "\n",
    "    b: The mean distance between a sample and all other points in the next nearest cluster.\n",
    "    \n",
    "    This index then describe both the within cluster and between cluster similarity.\n",
    "    \n",
    "    **Sorted similarity matrix**\n",
    "    \n",
    "    After computing the similarity matrix between all pairs of samples it is possible to sort it by the predicted label. If the clustering is good there will be more similar blocks on the diagonal and dissimilar blocks off the diagonal.\n",
    "\n",
    "For other info check the [scikit page](https://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation)\n",
    "\n",
    "<a id='fig3.3'></a>\n",
    "#### Fig. 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels = model.labels_\n",
    "print(\"Silhouette score: \",round(metrics.silhouette_score(X_mm, labels, metric='euclidean'),4))\n",
    "print(\"Adj Rand Index: \",round(metrics.adjusted_rand_score(y, labels),4))\n",
    "print(\"V-measure: \",round(metrics.v_measure_score(y, labels),4))\n",
    "print(\"Fowlkes-Mallows index: \",round(metrics.fowlkes_mallows_score(y, labels),4))\n",
    "\n",
    "print(\"CONTINGENCY MATRIX:\")\n",
    "plot_cm(y, labels, label_dict)\n",
    "\n",
    "sim = similarity_mat(X_mm, 'euclidean')\n",
    "plot_sorted_sim(sim, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Silhouette Score** the score is near to zero. This means that the clusters overlap. This is actually coherent with our findings, as the different labels corresponding to the injection and karyotype were not recognized. Thus, they were ovverlapping. The reason why this score is not too high might also rely behind the fact that the silhoutte score is generally higher when the clusters are convex, and this is not the case.\n",
    "- **ARI** should perform relatively good, as no assumption is made on the clusters. Even though the absolute value of this score is low, it is positive. Thus, they are similar clusterings.\n",
    "- **V-measure** This measure is mediocre showing that cluster are not so homogenoues nor complete.\n",
    "- **Fowlkes-Mallows index** according to this index, he clustering does not perform very accurately this is because, as we can see from the contingency matrix, the clustering is quite accurat on finding CS or SC classes but not the more specific ones. Therefore, Accuracy and recall will be quite low.\n",
    "\n",
    "The contingency matrix is coerent with the comments that were previously made regarding the subdivision of CS and SC classes.\n",
    "\n",
    "The Similarity matrix emphasizes the fact that the found clusters are not well-defined. Indeed, the score measures were not very promising. From the plot, it can be noticed that the squares plotted on the diagonal of the bigger square are not very ditinct when compared to the 'background'.\n",
    "\n",
    "Now, the hierarchical clustering is done on a different dataset. Indeed, only the control label will be analysed and subject to clustering. This has been done in order to reproduce the paper analysis. Of course, since only half of the original labels are taken into consideration, the number of clusters will be 4 and not 8 anymore.\\\n",
    "What we are hoping to obtain from  this second clustering, is a distinct subdivision of the data point in 4 of the 8 possible classes (c-CS-m, c-CS-t, c-SC-m, c-SC-t). We are expecting that there will be a first big subdivision among c-CS and c-SC.\n",
    "\n",
    "<a id='fig3.4'></a>\n",
    "#### Fig. 3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Z_c = linkage(X_c, metric='euclidean', method='ward')\n",
    "plot_dendrogram(Z=Z_c, X=X_c,truncate_mode='lastp', \n",
    "                p=50, n_clusters=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysing the diagrams of the different nodes that follow, we get to the follwing results.\\\n",
    "Most of the data points belonging to the CS classes are included in the clusters 5 and 4. In particular, cluster 5 is characterised by points belonging only to c-CS-m and c-CS-s. Differently, it is very hard to get to conclusions regarding cluster 9, as it does not include relevant distinction among the different labels. At last, cluster 7 is characterized by data points belonging to the SC class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(get_node(Z_c,X_c,y_c, -5, label_dict_c))\n",
    "print(get_node(Z_c,X_c,y_c, -4, label_dict_c))\n",
    "print(get_node(Z_c,X_c,y_c, -9, label_dict_c))\n",
    "print(get_node(Z_c,X_c,y_c, -7, label_dict_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fig3.5'></a>\n",
    "#### Fig. 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.set_params(n_clusters=4)\n",
    "\n",
    "y_predict = model.fit_predict(X_c)\n",
    "\n",
    "plot_clust_3d(X_c, y_c, full_train_c, y_predict, \"PCA on controls with hclust\")\n",
    "plot_clust_2d(X_c, y_c_cat, y_predict, \"PCA on controls with hclust\")\n",
    "\n",
    "labels = model.labels_\n",
    "print(\"Silhouette score: \",round(metrics.silhouette_score(X_c, labels, metric='euclidean'),4))\n",
    "print(\"Adj Rand Index: \",round(metrics.adjusted_rand_score(y_c, labels),4))\n",
    "print(\"V-measure: \",round(metrics.v_measure_score(y_c, labels),4))\n",
    "print(\"Fowlkes-Mallows index: \",round(metrics.fowlkes_mallows_score(y_c, labels),4))\n",
    "\n",
    "print(\"CONTINGENCY MATRIX:\")\n",
    "plot_cm(y_c, labels, label_dict_c)\n",
    "sim_c = similarity_mat(X_c, 'euclidean')\n",
    "plot_sorted_sim(sim_c, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous plots, the characteristics of the different clusters can be analysed. For example, looking at the two-dimentional plot, the Xs represent cluster 5. Furthermore, overall, there is a clear distinctions of the clusters that describe c-SC from the ones that describe c-CS.\n",
    "\n",
    "Compared to the previous hierarchical clustering, all of the analytical measures have improved. \n",
    "\n",
    "The contingency matrix shows the results that we were expecting. Two of the clusters are almost completely characterized by elements respectively from c-SC and c-CS. Furthermore, one of the clusters contains elements that are spread evenly among the different classes.\n",
    "\n",
    "The same conclusions can be deduced from the similarity matrix. The different cluters are not extremely well defined, especially the cluster represented at the bottom right of the diagonal, which indeed represents the worst-perfroming cluster of this specific method. \n",
    "\n",
    "Overall, this clustering performs relatively well when defining the differences among c-CS and c-SC.\n",
    "\n",
    "We perform the same clustering keeping only the selected proteins as features.\n",
    "\n",
    "<a id='fig3.6'></a>\n",
    "#### Fig. 3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Z_c_red = linkage(X_c_red, metric='euclidean', method='ward')\n",
    "plot_dendrogram(Z=Z_c_red, X=X_c_red,truncate_mode='lastp', \n",
    "                p=50, n_clusters=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(get_node(Z_c_red,X_c_red,y_c, -7, label_dict_c))\n",
    "# print(get_node(Z_c_red,X_c_red,y_c, -5, label_dict_c))\n",
    "# print(get_node(Z_c_red,X_c_red,y_c, -11, label_dict_c))\n",
    "# print(get_node(Z_c_red,X_c_red,y_c, -4, label_dict_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_predict_red = model.fit_predict(X_c_red)\n",
    "\n",
    "plot_clust_3d(X_c_red, y_c, full_train_c, y_predict_red, \"PCA on controls w/ reduced dims with hclust\")\n",
    "plot_clust_2d(X_c_red, y_c_cat, y_predict_red, \"PCA on controls w/ reduced dims with hclust\")\n",
    "\n",
    "labels = model.labels_\n",
    "print(\"Silhouette score: \",round(metrics.silhouette_score(X_c_red, labels, metric='euclidean'),4))\n",
    "print(\"Adj Rand Index: \",round(metrics.adjusted_rand_score(y_c, labels),4))\n",
    "print(\"V-measure: \",round(metrics.v_measure_score(y_c, labels),4))\n",
    "print(\"Fowlkes-Mallows index: \",round(metrics.fowlkes_mallows_score(y_c, labels),4))\n",
    "\n",
    "print(\"CONTINGENCY MATRIX:\")\n",
    "plot_cm(y_c, labels, label_dict_c)\n",
    "sim_c_red = similarity_mat(X_c_red, 'euclidean')\n",
    "plot_sorted_sim(sim_c_red, y_predict_red)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can in fact see that the clustering performs better even though it's still not able to correctly cluster karyotpye and injection type. This validates the disciminative proteins and, as expected, there is a more defined distinction between SC and CS classes.   \n",
    "\n",
    "The same hierarchical clustering has been made on the trisomic mice. As it will be noticed, the results are not as accurate as the previous example of control mice.\n",
    "\n",
    "<a id='fig3.7'></a>\n",
    "#### Fig. 3.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Z_t = linkage(X_t, metric='euclidean', method='ward')\n",
    "plot_dendrogram(Z=Z_t, X=X_t,truncate_mode='lastp', \n",
    "                p=50, n_clusters=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(get_node(Z_t,X_t,y_t, -6, label_dict_t))\n",
    "print(get_node(Z_t,X_t,y_t, -7, label_dict_t))\n",
    "print(get_node(Z_t,X_t,y_t, -8, label_dict_t))\n",
    "print(get_node(Z_t,X_t,y_t, -4, label_dict_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nodes 4 and 6 are not characteristic of any label, indeed they are composed by mixed data. Instead, the cluster 7 is mainly charcterized by CS label. Differently, the cluster corresponding to cluster 8 includes both t-CS-s and t-SC-s. This is coherent with the meaning of the different lables, indeed the trisomic mice with saline injection do not learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.set_params(n_clusters=4)\n",
    "y_predict = model.fit_predict(X_t)\n",
    "\n",
    "plot_clust_3d(X_t, y_t, full_train_t, y_predict, \"PCA on trisomic with hclust\")\n",
    "plot_clust_2d(X_t, y_t_cat, y_predict, \"PCA on trisomic with hclust\")\n",
    "\n",
    "labels = model.labels_\n",
    "print(\"Silhouette score: \",round(metrics.silhouette_score(X_t, labels, metric='euclidean'),4))\n",
    "print(\"Adj Rand Index: \",round(metrics.adjusted_rand_score(y_t, labels),4))\n",
    "print(\"V-measure: \",round(metrics.v_measure_score(y_t, labels),4))\n",
    "print(\"Fowlkes-Mallows index: \",round(metrics.fowlkes_mallows_score(y_t, labels),4))\n",
    "\n",
    "print(\"CONTINGENCY MATRIX:\")\n",
    "plot_cm(y_t, labels, label_dict_t)\n",
    "sim_t = similarity_mat(X_t, 'euclidean')\n",
    "plot_sorted_sim(sim_t, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indeces and the contingency and similarity matrices show that the performance is less accurate when compared to the hierarchical clustering done with control mice. Nevertheless, it is possible to notice that, as in the previous example, there is a subdivision of the CS and SC labels. In this example this is not as well defined, indeed it is actually more subtle.\\\n",
    "Furthermore, it can be inferred that there was a defined clusters for some of the mice that do not learn (t-CS-s and t-SC-s). This cluster does not include all of the mice that do not learn, but it includes only the ones that receive saline injection.\n",
    "\n",
    "We perform the same clustering keeping only the discriminative proteins as features.\n",
    "\n",
    "<a id='fig3.8'></a>\n",
    "#### Fig. 3.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Z_t_red = linkage(X_t_red, metric='euclidean', method='ward')\n",
    "plot_dendrogram(Z=Z_t_red, X=X_t_red,truncate_mode='lastp', \n",
    "                p=50, n_clusters=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(get_node(Z_t_red,X_t_red,y_t, -8, label_dict_t))\n",
    "# print(get_node(Z_t_red,X_t_red,y_t, -7, label_dict_t))\n",
    "# print(get_node(Z_t_red,X_t_red,y_t, -6, label_dict_t))\n",
    "# print(get_node(Z_t_red,X_t_red,y_t, -4, label_dict_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_predict_red = model.fit_predict(X_t_red)\n",
    "\n",
    "plot_clust_3d(X_t_red, y_t, full_train_t, y_predict_red, \"PCA on trisomic w/ reduced dims with hclust\")\n",
    "plot_clust_2d(X_t_red, y_t_cat, y_predict_red, \"PCA on trisomic w/ reduced dims with hclust\")\n",
    "\n",
    "labels = model.labels_\n",
    "print(\"Silhouette score: \",round(metrics.silhouette_score(X_t_red, labels, metric='euclidean'),4))\n",
    "print(\"Adj Rand Index: \",round(metrics.adjusted_rand_score(y_t, labels),4))\n",
    "print(\"V-measure: \",round(metrics.v_measure_score(y_t, labels),4))\n",
    "print(\"Fowlkes-Mallows index: \",round(metrics.fowlkes_mallows_score(y_t, labels),4))\n",
    "\n",
    "print(\"CONTINGENCY MATRIX:\")\n",
    "plot_cm(y_t, labels, label_dict_t)\n",
    "sim_t_red = similarity_mat(X_t_red, 'euclidean')\n",
    "plot_sorted_sim(sim_t_red, y_predict_red)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clustering performance increases when using only supposedly discriminative proteins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMEANS\n",
    "\n",
    "The k-means algorithm is one of the simplest unsupervised learning algorithm. To perform this clustering technique one has to choose k, which is the number of clusters that will be produced. K means basically finds k centroids and assign the datapoints to the cluster of the closest centroid. This algorithm is based on a random initialization, it always converges (but that could happen within a local optima) and it's pretty efficient. However, the main issues is that one has to decide the value of k and that results can vary based on the initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that we have 8 classes in our data Kmeans will be performed assuming k = 8. The initialization is 'k-means++' that ensures a smarter initialization of the centroids.\n",
    "\n",
    "<a id='fig3.9'></a>\n",
    "#### Fig. 3.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=8, init='k-means++', random_state=0)             \n",
    "\n",
    "y_predict = model.fit_predict(X_mm)\n",
    "\n",
    "labels = model.labels_\n",
    "plot_cm(y, labels, label_dict)\n",
    "\n",
    "print(\"Silhouette score: \",round(metrics.silhouette_score(X_mm, labels, metric='euclidean'),4))\n",
    "print(\"Adj Rand Index: \",round(metrics.adjusted_rand_score(y, labels),4))\n",
    "print(\"V-measure: \",round(metrics.v_measure_score(y, labels),4))\n",
    "print(\"Fowlkes-Mallows index: \",round(metrics.fowlkes_mallows_score(y, labels),4))\n",
    "\n",
    "sim = similarity_mat(X_mm, 'euclidean')\n",
    "\n",
    "plot_sorted_sim(sim, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the indices are comparable to the hierarchical clustering. As usual, the distinction between SC and CS is much more clear than the other classes. \\\n",
    "As before, we then perform clustering on only control samples.\n",
    "\n",
    "<a id='fig3.10'></a>\n",
    "#### Fig. 3.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_clust=4\n",
    "model.set_params(n_clusters=n_clust)\n",
    "\n",
    "y_predict = model.fit_predict(X_c)\n",
    "\n",
    "labels = model.labels_\n",
    "\n",
    "print(\"Silhouette score: \",round(metrics.silhouette_score(X_c, labels, metric='euclidean'),4))\n",
    "print(\"Adj Rand Index: \",round(metrics.adjusted_rand_score(y_c, labels),4))\n",
    "print(\"V-measure: \",round(metrics.v_measure_score(y_c, labels),4))\n",
    "print(\"Fowlkes-Mallows index: \",round(metrics.fowlkes_mallows_score(y_c, labels),4))\n",
    "\n",
    "plot_cm(y_c, labels, label_dict_c)\n",
    "plot_sorted_sim(sim_c, y_predict)\n",
    "\n",
    "y_predict = model.fit_predict(X_c_red)\n",
    "\n",
    "labels = model.labels_\n",
    "print(\"Silhouette score: \",round(metrics.silhouette_score(X_c_red, labels, metric='euclidean'),4))\n",
    "print(\"Adj Rand Index: \",round(metrics.adjusted_rand_score(y_c, labels),4))\n",
    "print(\"V-measure: \",round(metrics.v_measure_score(y_c, labels),4))\n",
    "print(\"Fowlkes-Mallows index: \",round(metrics.fowlkes_mallows_score(y_c, labels),4))\n",
    "\n",
    "plot_cm(y_c, labels, label_dict_c)\n",
    "plot_sorted_sim(sim_c_red, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The k-means algorithm seems to perform slightly better than hierarchical on only c samples. The v-measure increases and the 4 clusters seems more homogenous by looking at the contingency matrix. A cluster with all the 4 classes remains though. \\\n",
    "Then we perform clustering on only trisomic samples.\n",
    "\n",
    "<a id='fig3.11'></a>\n",
    "#### Fig. 3.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_predict = model.fit_predict(X_t)\n",
    "\n",
    "labels = model.labels_\n",
    "\n",
    "print(\"Silhouette score: \",round(metrics.silhouette_score(X_t, labels, metric='euclidean'),4))\n",
    "print(\"Adj Rand Index: \",round(metrics.adjusted_rand_score(y_t, labels),4))\n",
    "print(\"V-measure: \",round(metrics.v_measure_score(y_t, labels),4))\n",
    "print(\"Fowlkes-Mallows index: \",round(metrics.fowlkes_mallows_score(y_t, labels),4))\n",
    "\n",
    "plot_cm(y_t, labels, label_dict_t)\n",
    "plot_sorted_sim(sim_t, y_predict)\n",
    "\n",
    "y_predict = model.fit_predict(X_t_red)\n",
    "\n",
    "labels = model.labels_\n",
    "\n",
    "print(\"Silhouette score: \",round(metrics.silhouette_score(X_t_red, labels, metric='euclidean'),4))\n",
    "print(\"Adj Rand Index: \",round(metrics.adjusted_rand_score(y_t, labels),4))\n",
    "print(\"V-measure: \",round(metrics.v_measure_score(y_t, labels),4))\n",
    "print(\"Fowlkes-Mallows index: \",round(metrics.fowlkes_mallows_score(y_t, labels),4))\n",
    "\n",
    "plot_cm(y_t, labels, label_dict_t)\n",
    "plot_sorted_sim(sim_t_red, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also in this case k-means seems to perform better than hierarchical, with better Adj rand index and v measure. However as before trisomic samples seem to have a more complicated structure than controls.\n",
    "### DBSCAN\n",
    "DBSCAN is a density based clustering algorithm. This means that clusters are defined as density-connected points, for this reason algorithms like this can discover clusters of arbitrary shapes and handle noise. DBSCAN works with 2 parameters called eps and min samples. Eps represent the maximum radius of the neighborhood of a point. Min samples is the minimum number of points in the eps defined neighborhood to define a point a core point. This algorithm defines noise points without assigning them to any label if they are not a core point or into the neighborhood of a core point. A great advantage of this algorithm is that it is not needed to specify the number of clusters. \\\n",
    "Here we perform cross validation to define the two hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors # For Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are defining two main functions that will help us. Get_metrics is a function to evaluate the clustering produced. It outputs the number of clusters produced and the average distance between noise points and their 6 nearest neighbors. These metrics will vary based on the two hyperparameters. grid_dbscan performs the gridsearch and outputs two heatmaps that describe the two metrics based on the hyperparameters\n",
    "\n",
    "This code is greatly ispired by [this page](https://www.alessiovaccaro.com/resources/dbscan-grid-search.php#7.-Ricerca-degli-iperparametri) by Alessio Vaccaro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(eps, min_samples, dataset, iter_):\n",
    "    \n",
    "    # Fitting ======================================================================\n",
    "    \n",
    "    dbscan_model_ = DBSCAN( eps = eps, min_samples = min_samples)\n",
    "    dbscan_model_.fit(dataset)\n",
    "    \n",
    "    # Mean Noise Point Distance metric =============================================\n",
    "    noise_indices = dbscan_model_.labels_ == -1\n",
    "    \n",
    "    if True in noise_indices:\n",
    "        neighboors = NearestNeighbors(n_neighbors = 6).fit(dataset)\n",
    "        distances, indices = neighboors.kneighbors(dataset)\n",
    "        noise_distances = distances[noise_indices, 1:]\n",
    "        noise_mean_distance = round(noise_distances.mean(), 3)\n",
    "    else:\n",
    "        noise_mean_distance = None\n",
    "        \n",
    "    # Number of found Clusters metric ==============================================\n",
    "    \n",
    "    number_of_clusters = len(set(dbscan_model_.labels_[dbscan_model_.labels_ >= 0]))\n",
    "    \n",
    "    # Log ==========================================================================\n",
    "    \n",
    "    #print(\"%3d | Tested with eps = %3s and min_samples = %3s | %5s %4s\" % (iter_, eps, min_samples, \n",
    "                                                                           #str(noise_mean_distance), number_of_clusters))\n",
    "        \n",
    "    return(noise_mean_distance, number_of_clusters)\n",
    "\n",
    "def grid_dbscan(eps_to_test, min_samples_to_test, df):\n",
    "    results_noise = pd.DataFrame( \n",
    "    data = np.zeros((len(eps_to_test),len(min_samples_to_test))), # Empty dataframe\n",
    "    columns = min_samples_to_test, \n",
    "    index = eps_to_test\n",
    "    )\n",
    "\n",
    "# Dataframe per la metrica sul numero di cluster\n",
    "    results_clusters = pd.DataFrame( \n",
    "    data = np.zeros((len(eps_to_test),len(min_samples_to_test))), # Empty dataframe\n",
    "    columns = min_samples_to_test, \n",
    "    index = eps_to_test\n",
    "    )\n",
    "    iter_ = 0\n",
    "\n",
    "    for eps in eps_to_test:\n",
    "        for min_samples in min_samples_to_test:\n",
    "            iter_ += 1\n",
    "            # Calcolo le metriche\n",
    "            noise_metric, cluster_metric = get_metrics(eps, min_samples, df, iter_)\n",
    "            # Inserisco i risultati nei relativi dataframe\n",
    "            results_noise.loc[eps, min_samples] = noise_metric\n",
    "            results_clusters.loc[eps, min_samples] = cluster_metric\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,8) )\n",
    "\n",
    "    sns.heatmap(results_noise, annot = True, ax = ax1, cbar = False).set_title(\"METRIC: Mean Noise Points Distance\")\n",
    "    sns.heatmap(results_clusters, annot = True, ax = ax2, cbar = False).set_title(\"METRIC: Number of clusters\")\n",
    "\n",
    "    ax1.set_xlabel(\"N\"); ax2.set_xlabel(\"N\")\n",
    "    ax1.set_ylabel(\"EPSILON\"); ax2.set_ylabel(\"EPSILON\")\n",
    "\n",
    "    plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fig3.11'></a>\n",
    "#### Fig. 3.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_to_test = np.arange(1, 2.5, 0.1).tolist()\n",
    "min_samples_to_test = range(2,18)\n",
    "\n",
    "grid_dbscan(eps_to_test, min_samples_to_test,X_mm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For low values of eps (eps < 1.5) all points are classified as noise points whereas for values higher than 1.8 the algorithm produces only one cluster. There are few combinations of N and eps that produce possibly interesting clustering. \\\n",
    "We can try to use eps = 1.5 and N = 3 and fit the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dbscan_model = DBSCAN( eps = 1.6, min_samples = 3)\n",
    "\n",
    "# Fitting\n",
    "best_dbscan_model.fit(X_mm)\n",
    "\n",
    "# Extracting labels\n",
    "best_dbscan_model.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBSCAN seems to perform really poorly on our dataset even after trying to optimize its hyperparameters. This might be due to the fact that this algorithm suffers from high dimensionality, it also requires connected regions of sufficiently high density. For these reasons DBSCAN won't be explored further.\n",
    "\n",
    "### Conclusions\n",
    "In conclusion, the clustering performs satisfactorily in the subdivision among the CS and SC classes. This means that the context fear conditioning have a strong influence on protein expression. This strengthen the hyphothesis that fear, and not the actual learning might be the major contributor to expression variability. \\\n",
    "However, to undermine this conclusion, in control cases this distinction appeared more clear whereas the structure of trisomic mice seemed to be more complex just like the learning outcome. \\\n",
    "The discriminative proteins were validated as clustering with only those features increased the performance of the algorithm. \\\n",
    "Overall Kmeans performed better on this dataset.\n",
    "\n",
    "<a id='section_4'></a>\n",
    "# 4. Classification\n",
    "In order to classify mice from the 8 different classes we use supervised learning techniques that, starting from the input data, assign a label to each sample. Here we'll compare few different classification algorithms including:\n",
    "\n",
    "- Logistic regression\n",
    "- Support Vector Classifier (linear and poly kernel)\n",
    "- K Neighbors classifier (optimized parameters and default parameters)\n",
    "- Linear Discriminant Analysis\n",
    "- Quadratic Discriminant Analysis\n",
    "\n",
    "We'll use the standard scikit API to train and test the models. All models will be trained on MinMax scaled data. Furthermore, this is a multiclass classfication, scikit models implement this kind of problems out of the box so we don't need to worry about implementing them unless we would want to experiment with different multiclass strategies.\n",
    "\n",
    "Here we import the different functions/modules needed for this chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif, RFECV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to note that the protein SOD1 is removed from the training set because of its absence in the test set. As we've seen this protein seems quite important therefore we'll try to solve this problem and analyze its influence in chapter 5 and 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train.drop(\"SOD1_N\", axis=1)\n",
    "X_2 = np.array(train2.drop('class', axis=1))\n",
    "y_2 = np.array(train2['class'].cat.codes) #unsigned integers specifying group\n",
    "y_2_cat = np.array(train2['class'])\n",
    "\n",
    "X_test = np.array(test.drop('class', axis=1))\n",
    "y_test = np.array(test['class'].cat.codes)\n",
    "y_test_cat = np.array(test['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We optimize the KNN parameters: n_neighbors which is k, p which is the power parameter of the minkowski metric (1 means manatthan distance, 2 is euclidean distance). The weights parameter can be uniform if all points in the neighborhood are weighted equally or distance if it weighs closer neighbors more heavily than further neighbors. I also tested cosine distance, which is not a proper distance metric because as it violates the triangle inequality, but it could be a valuable alternative because it should work better with high dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_KNN = {\n",
    "    'n_neighbors': list(range(5,20)),\n",
    "    'p': (1,2,3,4),\n",
    "    'weights': ('uniform', 'distance'),\n",
    "    'metric': ('minkowski','cosine')\n",
    "}\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# with GridSearch\n",
    "grid_search_KNN = GridSearchCV(\n",
    "    estimator=knn,\n",
    "    param_grid=parameters_KNN,\n",
    "    scoring = 'accuracy',\n",
    "    n_jobs = -1,\n",
    "    cv = 5\n",
    ")\n",
    "\n",
    "pipe = Pipeline(steps=[('scaler', scaler),('m',grid_search_KNN)])\n",
    "\n",
    "pipe.fit(X_2, y_2)\n",
    "print(\"The best parametrs are \\n:\",grid_search_KNN.best_params_ ) \n",
    "print('Best Score - KNN:', grid_search_KNN.best_score_ )\n",
    "params = grid_search_KNN.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also test 2 different kernels for the SVM algortihm. The kernel is the function that transform the input data into a kernel-specific form. Here linear and polynomial kernels are tested.\n",
    "\n",
    "All the algorithms are evaluated on test accuracy, classification report and test contingency matrix. \n",
    "\n",
    "<a id='fig4.1'></a>\n",
    "#### Fig. 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "models = [LogisticRegression(),\n",
    "          SVC(kernel='linear'),\n",
    "          SVC(kernel='poly'),\n",
    "          KNeighborsClassifier(n_neighbors=10),\n",
    "          KNeighborsClassifier(**params),\n",
    "          LinearDiscriminantAnalysis(store_covariance=True),\n",
    "          QuadraticDiscriminantAnalysis(store_covariance=True)]\n",
    "\n",
    "#cols=[\"Classifier\", \"Accuracy\"]\n",
    "whole_class = []\n",
    "for model in models:\n",
    "    clf = Pipeline(steps=[('scaler', scaler),('m',model)])\n",
    "    clf.fit(X_2, y_2)\n",
    "    name = model.__class__.__name__\n",
    "    print(\"=\"*60)\n",
    "    print(name)\n",
    "    print('****Results****')\n",
    "    test_predictions = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, test_predictions)\n",
    "    whole_class.append(acc)\n",
    "    print(\"Accuracy: {:.4%}\".format(acc))\n",
    "    print(classification_report(y_test, test_predictions))\n",
    "    plot_cm(y_test, test_predictions, label_dict)\n",
    "    plt.show()\n",
    "    #entry = pd.DataFrame([[name, acc*100]], columns=log_cols)\n",
    "    \n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression does not perform well especially on CS classes, it also fails to converge. The two SVC algorithms perform similarly and have the same problems classifing CS classes. KNN performes worse than the previous algorithms and has problems with CS and t-SC classes. LDA is the one with the highest test accuracy (82%). Instead, QDA performs really bad, this might be due to collinear variables (it also gives a warning about this) so this method would probably be the one that benefits the most from feature selection. \\\n",
    "We then test the same models removing only highly correlated features (|r|>0.8). This should help improve QDA algrotihm. Correlated features cause multicollinearity that can lead to less precise estimates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# drop 1 of 2 highly correlated features\n",
    "\n",
    "print(X_2.shape)\n",
    "\n",
    "X_2_df = train2.drop('class', axis=1)\n",
    "corr = X_2_df.corr()\n",
    "\n",
    "threshold = 0.8\n",
    "\n",
    "columns = np.full((corr.shape[0],), True, dtype=bool)\n",
    "for i in range(corr.shape[0]):\n",
    "    for j in range(i+1, corr.shape[0]):\n",
    "        if abs(corr.iloc[i,j]) >= threshold:\n",
    "            if columns[j]:\n",
    "                columns[j] = False                \n",
    "selected_columns = X_2_df.columns[columns]\n",
    "removed_columns = X_2_df.columns[~columns]\n",
    "print(\"removed:\", list(removed_columns))\n",
    "\n",
    "train2_nocor = train2[selected_columns]\n",
    "train2_class_nocor = train2.drop(removed_columns, axis=1)\n",
    "test2_nocor = test[selected_columns]\n",
    "print(train2_nocor.shape)\n",
    "\n",
    "X_2_nocorr = np.array(train2_nocor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 proteins ( 'pERK_N', 'BRAF_N', 'ERK_N', 'Bcatenin_N') were removed from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('scaler', scaler),('m',grid_search_KNN)])\n",
    "pipe.fit(X_2_nocorr, y_2)\n",
    "\n",
    "print(grid_search_KNN.best_params_ ) \n",
    "print('Best Score - KNN:', grid_search_KNN.best_score_ )\n",
    "\n",
    "params = grid_search_KNN.best_params_\n",
    "knn_opt = KNeighborsClassifier(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fig4.2'></a>\n",
    "#### Fig. 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "models = [LogisticRegression(),\n",
    "          SVC(kernel='linear'),\n",
    "          SVC(kernel='poly'),\n",
    "          KNeighborsClassifier(n_neighbors=10),\n",
    "          KNeighborsClassifier(**params),\n",
    "          LinearDiscriminantAnalysis(store_covariance=True),\n",
    "          QuadraticDiscriminantAnalysis(store_covariance=True)]\n",
    "\n",
    "#cols=[\"Classifier\", \"Accuracy\"]\n",
    "no_corr_class = []\n",
    "for model in models:\n",
    "    clf = Pipeline(steps=[('scaler', scaler),('m',model)])\n",
    "    clf.fit(X_2_nocorr, y_2)\n",
    "    name = model.__class__.__name__\n",
    "    print(\"=\"*60)\n",
    "    print(name)\n",
    "    print('****Results****')\n",
    "    test_predictions = clf.predict(test2_nocor)\n",
    "    acc = accuracy_score(y_test, test_predictions)\n",
    "    no_corr_class.append(acc)\n",
    "    print(\"Accuracy: {:.4%}\".format(acc))\n",
    "    print(classification_report(y_test, test_predictions))\n",
    "    plot_cm(y_test, test_predictions, label_dict)\n",
    "    plt.show()\n",
    "    #entry = pd.DataFrame([[name, acc*100]], columns=log_cols)\n",
    "    \n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This however does not seem to increase the accuracy of the different models.\n",
    "## Feature selection\n",
    "Therefore, to increase the accuracy we resort to feature selection. These methods help create more accurate models by selecting important and informative features and removing redundant ones that may decrease the accuracy of the model. Furthermore, they reduce the complexity of the model.\n",
    "### Univariate feature selection:\n",
    "\n",
    "This approach is based on statistical tests to select the features which have the strongest relationship with the output class. These methods are really fast and generally they are good at removing non informative, correlated or constant features. However, they are univariate, so they assess each feature independently from the others and this could cause redundant features to be selected as they don't consider interaction between variables. \\\n",
    "First of all, we perform the scikit implementation of the f-classif scorer, this means that for each variable will be performed an ANOVA test. The results of this test is the F-value which basically explicit how the means of the numerical feature differs for each group. We start by using all the features and selecting the features with an f-score greater than the 75th percentile.\n",
    "\n",
    "<a id='fig4.3'></a>\n",
    "#### Fig. 4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ANOVA feature selection for numeric input and categorical output\n",
    "fs = SelectKBest(score_func=f_classif, k='all')\n",
    "\n",
    "fs.fit(X_2, y_2)\n",
    "X_train_fs = fs.transform(X_2)\n",
    "\n",
    "# transform test input data\n",
    "# what are scores for the features\n",
    "max_score = np.percentile(fs.scores_, 75) \n",
    "k = sum(fs.scores_ > max_score)\n",
    "\n",
    "plt.boxplot(fs.scores_)\n",
    "plt.axhline(y=max_score, color = \"firebrick\", linestyle = \"dashed\")\n",
    "plt.show()\n",
    "plt.bar([i for i in range(len(fs.scores_))], np.sort(fs.scores_))\n",
    "plt.axvline(x=fs.scores_.shape[0]-k, color = \"firebrick\", linestyle = \"dashed\")\n",
    "plt.show()\n",
    "\n",
    "# define feature selection\n",
    "fs = SelectKBest(score_func=f_classif, k=k)\n",
    "# apply feature selection\n",
    "X_selected_fs = fs.fit_transform(X_2, y)\n",
    "\n",
    "# Show results\n",
    "print('Original number of features:', X_2.shape[1])\n",
    "print('Reduced number of features:', X_selected_fs.shape[1])\n",
    "\n",
    "mask = fs.get_support()\n",
    "features_f = X_2_df.columns[mask]\n",
    "print(features_f)\n",
    "print(X_selected_fs.shape)\n",
    "#The F-value scores examine if, when we group the numerical\n",
    "#feature by the target vector, the means for each group are significantly different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case 19 features were selected. We then perform the same classification pipeline as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('scaler', scaler),('m',grid_search_KNN)])\n",
    "pipe.fit(X_selected_fs, y)\n",
    "\n",
    "print(grid_search_KNN.best_params_ ) \n",
    "print('Best Score - KNN:', grid_search_KNN.best_score_ )\n",
    "\n",
    "params = grid_search_KNN.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fig4.4'></a>\n",
    "#### Fig. 4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_test_fs = test[features_f]\n",
    "\n",
    "models = [LogisticRegression(),\n",
    "          SVC(kernel='linear'),\n",
    "          SVC(kernel='poly'),\n",
    "          KNeighborsClassifier(n_neighbors=10),\n",
    "          KNeighborsClassifier(**params),\n",
    "          LinearDiscriminantAnalysis(store_covariance=True),\n",
    "          QuadraticDiscriminantAnalysis(store_covariance=True)]\n",
    "\n",
    "#cols=[\"Classifier\", \"Accuracy\"]\n",
    "univ_class = []\n",
    "for model in models:\n",
    "    clf = Pipeline(steps=[('scaler', scaler),('m',model)])\n",
    "    clf.fit(X_selected_fs, y_2)\n",
    "    name = model.__class__.__name__\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(name)\n",
    "    \n",
    "    print('****Results****')\n",
    "    \n",
    "    test_predictions = clf.predict(X_test_fs)\n",
    "    acc = accuracy_score(y_test, test_predictions)\n",
    "    univ_class.append(acc)\n",
    "    print(\"Accuracy: {:.4%}\".format(acc))\n",
    "    print(classification_report(y_test, test_predictions))\n",
    "    test_predictions = clf.predict(X_test_fs)\n",
    "    plot_cm(y_test, test_predictions, label_dict)\n",
    "    plt.show()\n",
    "    #entry = pd.DataFrame([[name, acc*100]], columns=cols)\n",
    "    \n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the test accuracy greatly increases in all methods. Reaching very good values in SVC-poly, optimized KNN and QDA. QDA, as expected, is the method with the greatest increase in performance.\n",
    "### Recursive feature elimination\n",
    "\n",
    "This method works by recursively removing attributes. It can be used only with classifiers that explicit feature importance. In our case we used linear SVC. At the beginning it uses all the data features deriving each feature importance. Remove the least important feature and retrain the model, calculating the performance metrics (in our case we used accuracy). Test if the performance decreases significantly. Finally repeat previous steps until all features are evaluated. \n",
    "We used this method because its easier implementation in scikt with respect to forward and backward selection.\n",
    "\n",
    "Here we perform RFE with stradifield 10 fold validation to find the optimal number of features.\n",
    "\n",
    "<a id='fig4.5'></a>\n",
    "#### Fig. 4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# recursive\n",
    "# pipeline = Pipeline(steps=[('scaler', StandardScaler()),('svc', model)])\n",
    "model = SVC(kernel=\"linear\")\n",
    "# The \"accuracy\" scoring is proportional to the number of correct\n",
    "# classifications\n",
    "rfecv = RFECV(estimator=model, step=1, cv=StratifiedKFold(10),\n",
    "              scoring='accuracy')\n",
    "\n",
    "pipeline = Pipeline(steps=[('scaler', scaler),('s',rfecv),('m',model)])\n",
    "\n",
    "pipeline.fit(X_2, y_2)\n",
    "\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()\n",
    "\n",
    "mask = rfecv.get_support()\n",
    "features_rfe = X_2_df.columns[mask]\n",
    "print(features_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = set(features_rfe)\n",
    "b = set(features_f)\n",
    "\n",
    "print(\"Union: \", len(a|b))\n",
    "print(\"Intersection: \", len(a & b))\n",
    "print(\"Intersection: \", a & b)\n",
    "      \n",
    "print(\"Difference rfe-univ: \", len(a - b))\n",
    "print(\"Difference rfe-univ: \", a - b)\n",
    "\n",
    "print(\"Difference: univ-rfe\", len(b - a))\n",
    "print(\"Difference: univ-rfe\", (b - a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the difference between the two sets of selected proteins. It is important to note that RFE includes also Bcatenin and ERK which are 2 of the 4 highly correlated proteins. This may cause problems in some methods.\\\n",
    "Now we train the models with the RFE features as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test_rfe = test[features_rfe]\n",
    "print(X_test_rfe.shape)\n",
    "# X_selected.shape\n",
    "X_selected_rfe = train2[features_rfe]\n",
    "print(X_selected_rfe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('scaler', scaler),('m',grid_search_KNN)])\n",
    "pipe.fit(X_selected_rfe, y_2)\n",
    "\n",
    "print(grid_search_KNN.best_params_ ) \n",
    "print('Best Score - KNN:', grid_search_KNN.best_score_ )\n",
    "\n",
    "params = grid_search_KNN.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fig4.6'></a>\n",
    "#### Fig. 4.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "models = [LogisticRegression(),\n",
    "          SVC(kernel='linear'),\n",
    "          SVC(kernel='poly'),\n",
    "          KNeighborsClassifier(n_neighbors=10),\n",
    "          KNeighborsClassifier(**params),\n",
    "          LinearDiscriminantAnalysis(store_covariance=True),\n",
    "          QuadraticDiscriminantAnalysis(store_covariance=True)]\n",
    "\n",
    "#cols=[\"Classifier\", \"Accuracy\"]\n",
    "rfe_class = []\n",
    "for model in models:\n",
    "    clf = Pipeline(steps=[('scaler', scaler),('m',model)])\n",
    "    clf.fit(X_selected_rfe, y_2)\n",
    "    name = model.__class__.__name__\n",
    "    print(\"=\"*60)\n",
    "    print(name)\n",
    "    print('****Results****')\n",
    "    test_predictions = clf.predict(X_test_rfe)\n",
    "    acc = accuracy_score(y_test, test_predictions)\n",
    "    rfe_class.append(acc)\n",
    "    print(\"Accuracy: {:.4%}\".format(acc))\n",
    "    print(classification_report(y_test, test_predictions))\n",
    "    plot_cm(y_test, test_predictions, label_dict)\n",
    "    plt.show()\n",
    "    #entry = pd.DataFrame([[name, acc*100]], columns=log_cols)\n",
    "    \n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performances are similar to the the previous models except for QDA which might suffer from the two correlated variables, for this reason we perform the same procedure on the dataset with no correlated variables.\n",
    "\n",
    "<a id='fig4.7'></a>\n",
    "#### Fig. 4.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel=\"linear\")\n",
    "# The \"accuracy\" scoring is proportional to the number of correct\n",
    "# classifications\n",
    "rfecv = RFECV(estimator=model, step=1, cv=StratifiedKFold(10),\n",
    "              scoring='accuracy')\n",
    "\n",
    "pipeline = Pipeline(steps=[('scaler', scaler),('s',rfecv),('m',model)])\n",
    "\n",
    "pipeline.fit(X_2_nocorr, y_2)\n",
    "\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()\n",
    "\n",
    "mask = rfecv.get_support()\n",
    "features_rfe = train2_nocor.columns[mask]\n",
    "print(features_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_nocorr = test[selected_columns]\n",
    "X_test_nocorr_fs = X_test_nocorr[features_rfe]\n",
    "X_nocorr_rfe = X_2_df[features_rfe]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fig4.8'></a>\n",
    "#### Fig. 4.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "no_corr_rfe_class = []\n",
    "for model in models:\n",
    "    clf = Pipeline(steps=[('scaler', scaler),('m',model)])\n",
    "    clf.fit(X_nocorr_rfe, y_2)\n",
    "    name = model.__class__.__name__\n",
    "    print(\"=\"*60)\n",
    "    print(name)\n",
    "    print('****Results****')\n",
    "    test_predictions = clf.predict(X_test_nocorr_fs)\n",
    "    acc = accuracy_score(y_test, test_predictions)\n",
    "    no_corr_rfe_class.append(acc)\n",
    "    print(\"Accuracy: {:.4%}\".format(acc))\n",
    "    print(classification_report(y_test, test_predictions))\n",
    "    plot_cm(y_test, test_predictions, label_dict)\n",
    "    plt.show()\n",
    "    #entry = pd.DataFrame([[name, acc*100]], columns=log_cols)\n",
    "    \n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QDA performance raise again and the others remain more or less similar. \n",
    "### Conclusions\n",
    "The test accuracies of the models performed on different subset of features are summarised on the following barplot.\n",
    "\n",
    "<a id='fig4.9'></a>\n",
    "#### Fig. 4.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_corr_class = np.array(no_corr_class).reshape(1,-1)\n",
    "whole_class = np.array(whole_class).reshape(1,-1)\n",
    "univ_class = np.array(univ_class).reshape(1,-1)\n",
    "rfe_class = np.array(rfe_class).reshape(1,-1)\n",
    "no_corr_rfe_class = np.array(no_corr_rfe_class).reshape(1,-1)\n",
    "\n",
    "values = np.concatenate((whole_class,no_corr_class,univ_class,rfe_class,no_corr_rfe_class))\n",
    "names = ['Log-Reg','SVC-Linear','SVC-poly', 'KNN', 'KNN-opt', 'LDA', 'QDA']\n",
    "rows = ['all', 'nocorr', 'univ', 'rfe', 'rfe_nocor']\n",
    "\n",
    "df_acc = pd.DataFrame(values, columns=names, index=rows)\n",
    "df_acc = df_acc.reset_index().rename(columns={'index': 'features'})\n",
    "df_acc = df_acc.melt(id_vars='features', var_name='model', value_name='acc')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9,4))\n",
    "ax.yaxis.grid(True)\n",
    "sns.barplot(x=\"features\", y=\"acc\", hue=\"model\", edgecolor = 'k',\n",
    "            palette=sns.color_palette(\"Set2\", 7), \n",
    "            data=df_acc)\n",
    "plt.legend(bbox_to_anchor=(1.05, 0.7), loc=2, borderaxespad=0.)\n",
    "plt.ylim(0, 1)\n",
    "ax.set_title('Test Accuracy for different algorithms')\n",
    "ax.set_ylabel('Test Acc.')\n",
    "ax.set_yticks(np.arange(0,1.1,0.1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that all feature selection methods greatly increase the performance of the models and that SVC-poly, KNN-optimized and QDA with non correlated features are the best models with >90% test accuracy.\n",
    "\n",
    "<a id='section_5'></a>\n",
    "# 5. Regression\n",
    "\n",
    "To recover the information of SOD1 protein we are going to impute its missing value. We are going to do this by modeling it as a response in a simple multivariate regression context. This method to impute missing data has the advantage of using a lot of information to recover the missing info but it reduces the inherent variability of the data because it's deterministic. Therefore the imputed values will uniquely depend on the values of all the other features (ideally two mice with the same identical measures would have the same outcome). The random error is not be considered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.feature_selection import RFECV, f_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we see how this protein is distributed in the classes. We have already assessed that this is an importan protein, in fact it has high interclass variability. [(vd Fig 2.4)](#fig2.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.violinplot(x=\"class\", y=\"SOD1_N\", data=train, palette=\"Pastel1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CS classes have similar expression values much lower than the SC classes where the values are also more variable. \\\n",
    "We study what are the most correlated proteins to SOD1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Sod_rank = corr_df['SOD1_N'].rank()\n",
    "print(Sod_rank.loc[removed_columns])\n",
    "\n",
    "print(removed_columns)\n",
    "# create dataframe for regression\n",
    "\n",
    "X_reg = train2\n",
    "y_reg = train['SOD1_N']\n",
    "\n",
    "X_test_df = np.array(test)\n",
    "\n",
    "y_test_cat = np.array(test['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 of 4 removed columns due to correlation (pERK and BRAF) are in the 3 most correlated proteins to SOD1 so this means that we should include them in the regression as they should contain a lot of information regarding the response we are trying to predict. \\\n",
    "We are including the class variable in the model because, as we have seen, its expression varies a lot inter-class in the training set. However, it is important to notice that this might be seen as a controversy as, later,  we will use the imputed values to predict the class. Neverthless, assuming that the class variable is not important wouldn't have led to accurate results. \\\n",
    "The class variable will be coded with one hot encoding technique. This means that for each class there will be a column specifying its presence/absence (1/0). \\\n",
    "Given that we do not have any test set to validate our models we split the train dataset in train and test with a proportion of 70%/30%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df = pd.get_dummies(X_reg,prefix=['class'], columns = ['class'])\n",
    "\n",
    "split_seed = 42\n",
    "split_test_size = 0.3\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reg, y_reg, test_size=split_test_size,random_state=split_seed)\n",
    "\n",
    "print(dummy_df.iloc[:,-8:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we perform ordinary multivariate linear regression using all the features. We preprocess the data min max scaling numeric features and one hot encoding the class variable. Scaling with OLS does not change the result, however these preprocessing pipeline will also be applied to Ridge and Lasso regression that require standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()\n",
    "scaler = MinMaxScaler()\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "\n",
    "numeric_features = list(X_reg.columns[:-1])\n",
    "numeric_transformer = Pipeline(steps=[('scaler', scaler)])\n",
    "\n",
    "categorical_features = ['class']\n",
    "categorical_transformer = Pipeline(steps=[('onehot', encoder)])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('regression', model)])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_train_predict = clf.predict(X_train)  \n",
    "y_test_predict = clf.predict(X_test)  \n",
    "\n",
    "train_mse = mean_squared_error(y_train, y_train_predict)\n",
    "test_mse = mean_squared_error(y_test, y_test_predict)\n",
    "train_r2 = r2_score(y_train, y_train_predict)\n",
    "test_r2 = r2_score(y_test, y_test_predict)\n",
    "\n",
    "print(\"Train MSE: \", train_mse)\n",
    "print(\"Test MSE: \", test_mse)\n",
    "\n",
    "print(\"Train R2: \", train_r2)\n",
    "print(\"Test R2: \", test_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train R2 is really high as expect by such complex model that is really likely to overfit, however the test R2 is not so bad. Probably feature selection or regularization will help reduce the overfitting problem. \\\n",
    "### Univariate feature selection\n",
    "This feature selection process is similar to the one we did before in the classification context. Scikit implements the ANOVA F-test pipeline also for regression. This time the scorer is f_regression. But the main ideas behind it are the same: the feature importance is proportional to the correlation between each regressor and the target and it is represented by a F-score. We choose the feature with a F-score greater than the 75th percentile.\n",
    "\n",
    "<a id='fig5.1'></a>\n",
    "#### Fig. 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# correlation selection\n",
    "fs = SelectKBest(score_func=f_regression, k='all')\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('fs', fs)])\n",
    "\n",
    "# learn relationship from training data\n",
    "clf.fit(X_train, y_train)\n",
    "# transform train input data\n",
    "X_train_fs = clf.transform(X_train)\n",
    "# transform test input data\n",
    "\n",
    "max_score = np.percentile(fs.scores_, 75) \n",
    "k = sum(fs.scores_ > max_score)\n",
    "\n",
    "plt.boxplot(fs.scores_)\n",
    "plt.axhline(y=max_score, color = \"firebrick\", linestyle = \"dashed\")\n",
    "plt.show()\n",
    "plt.bar([i for i in range(len(fs.scores_))], np.sort(fs.scores_))\n",
    "plt.axvline(x=fs.scores_.shape[0]-k, color = \"firebrick\", linestyle = \"dashed\")\n",
    "plt.show()\n",
    "\n",
    "# define feature selection\n",
    "fs.set_params(k=k)\n",
    "# apply feature selection\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "X_train_fs = clf.transform(X_train)\n",
    "X_test_fs = clf.transform(X_test)\n",
    "\n",
    "# Show results\n",
    "\n",
    "print('Original number of features:', X_train.shape[1])\n",
    "print('Reduced number of features:', X_train_fs.shape[1])\n",
    "\n",
    "mask = fs.get_support()\n",
    "features_f_reg = dummy_df.columns[mask]\n",
    "print(features_f_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that all 8 classes are selected plus 13 proteins (including, as expected, pERK and BRAF). \\\n",
    "We then perform linear regression with the selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train_fs, y_train)\n",
    "\n",
    "y_predict = model.predict(X_test_fs)  \n",
    "\n",
    "print(\"Test R2 score: \", r2_score(y_test, y_predict))\n",
    "print(\"Test MSE score: \", mean_squared_error(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test R2 got a little better, this is because we reduced overfitting by reducing the complexity of the model. \n",
    "### Ridge regression\n",
    "This model solves linear regression problems with l2 regularization. This is done to obtain a better bias-variance trade off, meaning that, given the complexity of the model (high variance), we introduce some bias by shrinking the coefficients to reduce significantly the variance. The strength of this process depends on a parameter that describe the l2 regularization. The higher this parameter the stronger the regularization, if this is set to 0 the regression is just like an ordinary least squares. \\\n",
    "In scikit this parameter is called alpha. We use RidgeCV implementation to search the best alpha for our data using r2 as the scoring metric.\n",
    "\n",
    "<a id='fig5.2'></a>\n",
    "#### Fig. 5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alphas = 10**np.linspace(4,-2,100)*0.5\n",
    "\n",
    "ridge = Ridge(fit_intercept=True)\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('ridge', ridge)])\n",
    "\n",
    "coefs = []\n",
    "\n",
    "for a in alphas:\n",
    "    ridge.set_params(alpha = a)\n",
    "    clf.fit(X_train, y_train)\n",
    "    coefs.append(ridge.coef_)\n",
    "    \n",
    "np.shape(coefs)\n",
    "\n",
    "ridgecv = RidgeCV(alphas = alphas, scoring = 'r2', fit_intercept=False)\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('ridgecv', ridgecv)])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "ridgecv.alpha_\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.axis('tight')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')\n",
    "plt.axvline(x=ridgecv.alpha_)\n",
    "plt.show()\n",
    "print(ridgecv.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ridge_def = Ridge(alpha = ridgecv.alpha_, fit_intercept=True)\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('ridgedef', ridge_def)])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Test MSE: \",mean_squared_error(y_test, clf.predict(X_test)))\n",
    "print(\"Test R2: \",r2_score(y_test, clf.predict(X_test)))\n",
    "\n",
    "clf.fit(X_reg, y_reg)\n",
    "\n",
    "coef_ridge = pd.DataFrame(ridge_def.coef_, index = dummy_df.columns, columns=['Coef'])\n",
    "print(coef_ridge.tail(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Ridge regression with cross validated alpha we obtain a slight increase in performance with respect to the normal model and we obtain the same R2 than the model with the selected features.\n",
    "### Lasso regression\n",
    "Lasso regression has the same objective of ridge regression but it solves regression problems with l1 regularization. The main difference between the two techniques is that lasso can set the value of a coefficient to 0, therefore selecting important features. Ridge regression coefficients only tend to 0 asymptotically. Lasso should work better than ridge if there are few important features whereas ridge should work better if the majority of the features are influencing the response. \\\n",
    "We set the alpha parameter after selecting it through cross validation.\n",
    "\n",
    "<a id='fig5.3'></a>\n",
    "#### Fig. 5.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# lasso\n",
    "alphas = 10**np.linspace(1,-4,100)*0.5\n",
    "\n",
    "lasso = Lasso(fit_intercept=True)\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('lasso', lasso)])\n",
    "coefs = []\n",
    "\n",
    "for a in alphas:\n",
    "    lasso.set_params(alpha=a)\n",
    "    clf.fit(X_train, y_train)\n",
    "    coefs.append(lasso.coef_)\n",
    "\n",
    "    \n",
    "lassocv = LassoCV(alphas = alphas, cv = 10, fit_intercept=True)\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('lassocv', lassocv)])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "lasso.set_params(alpha=lassocv.alpha_)    \n",
    "    \n",
    "ax = plt.gca()\n",
    "ax.plot(alphas*2, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.axis('tight')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')\n",
    "plt.axvline(x=lassocv.alpha_)\n",
    "plt.show()\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('lasso', lasso)])\n",
    "clf.fit(X_train, y_train)\n",
    "y_predict_lassocv = clf.predict(X_test)\n",
    "\n",
    "print(\"Test MSE:\",mean_squared_error(y_test, y_predict_lassocv))\n",
    "print(\"Test R2: \", r2_score(y_test, clf.predict(X_test)))\n",
    "\n",
    "clf.fit(X_reg, y_reg)\n",
    "\n",
    "coef_lasso = pd.DataFrame(lasso.coef_, index = dummy_df.columns, columns=['Coef'])\n",
    "print(coef_lasso.tail(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fig5.4'></a>\n",
    "#### Fig. 5.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(sum(coef_lasso['Coef']==0), \"removed features\")\n",
    "print(sum(coef_lasso['Coef']!=0), \"features kept\")\n",
    "small_coef = sum(coef_lasso['Coef']<0.0001)-sum(coef_lasso['Coef']==0)\n",
    "print(small_coef, \"features with coeff < 0.0001\")\n",
    "\n",
    "plt.boxplot(coef_lasso['Coef'])\n",
    "plt.show()\n",
    "\n",
    "print(coef_lasso\n",
    " .assign(abs_coef=coef_lasso.Coef.abs())\n",
    " .sort_values('abs_coef', ascending=False)\n",
    " .head(15))\n",
    "#coef_lasso.sort_values(by=['Coef'], ascending=False).head(10)\n",
    "#sns.violinplot(x=\"class\", y=\"SOD1_N\", data=train, palette=\"Pastel1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that 36 features were removed and 24 features have a really small coefficent (<0.0001). The final number of features is 47. The test R2 increased to 0.8 so a slight increase with respect to ridge regression. \\\n",
    "### Recursive feature elimination\n",
    "It is also possible to implement recursive feature elimination, as seen in classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# feature selection rfcv\n",
    "ols = LinearRegression()\n",
    "\n",
    "rfecv = RFECV(estimator=ols, step=1, scoring='r2')\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('rfecv', rfecv)])\n",
    "\n",
    "# Fit recursive feature eliminator \n",
    "#clf.fit(X_train, y_train)\n",
    "\n",
    "# Recursive feature elimination\n",
    "X_train_rfe = clf.fit_transform(X_train, y_train)\n",
    "X_test_rfe = clf.transform(X_test)\n",
    "\n",
    "#rfecv.n_features_\n",
    "\n",
    "ols.fit(X_train_rfe, y_train)\n",
    "y_predict = ols.predict(X_test_rfe) \n",
    "\n",
    "print(\"Test R2 score: \", r2_score(y_test, y_predict))\n",
    "print(\"Test MSE score: \", mean_squared_error(y_test, y_predict))\n",
    "\n",
    "mask = rfecv.support_\n",
    "features_reg_rfe = dummy_df.columns[mask]\n",
    "print(features_reg_rfe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also this regression has a slight increase in test R2 but lower than lasso and ridge. \n",
    "\n",
    "### Conclusions \n",
    "\n",
    "After all we decided that the best regression between those performed is the lasso. The test R2 and MSE got slightly better performance with all the regularization/feature selection methods. The lasso had the best increase, even if with a little margin. Furthermore, the Lasso strong reduction of the model variance (through feature selection and regularization) should allow the model to perform acceptably on the test data. However, the maximum test R2 reached is 0.8 so there is still an unexplained portion of the variance that will influence the downstream analysis.\n",
    "\n",
    "<a id='section_6'></a>\n",
    "# 6. Classification with SOD1\n",
    "After imputing the missing values of SOD1 in the test data we can use this information to determine how this protein influences the performance of our previously found classifiers. \\\n",
    "We first train out optimized lasso model with all the training data and then we impute the missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('lasso', lasso)])\n",
    "\n",
    "clf.fit(X_reg, y_reg)\n",
    "\n",
    "y_predict_lassocv = clf.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOD_index = train.columns.get_loc(\"SOD1_N\")\n",
    "test_final = test.copy()\n",
    "\n",
    "test_final.insert(SOD_index, 'SOD1_N', y_predict_lassocv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our best models were SVC-poly and optimized KNN with rfe and QDA with rfe + no corr [(vd Fig 4.9)](#fig4.9). We then add SOD1 to the features to train the classifiers we tested before. At first on the RFE selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_def = features_rfe.copy()\n",
    "features_def = list(features_def)\n",
    "features_def.append('SOD1_N')\n",
    "\n",
    "train_final_rfe = train[features_def]\n",
    "test_final_rfe = test_final[features_def]\n",
    "\n",
    "y_test = np.array(test['class'].cat.codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('scaler', scaler),('m',grid_search_KNN)])\n",
    "\n",
    "pipe.fit(train_final_rfe, y)\n",
    "print(grid_search_KNN.best_params_ ) \n",
    "print('Best Score - KNN:', grid_search_KNN.best_score_ )\n",
    "params = grid_search_KNN.best_params_\n",
    "knn_opt = KNeighborsClassifier(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fig6.1'></a>\n",
    "#### Fig. 6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "models = [LogisticRegression(),\n",
    "          SVC(kernel='linear'),\n",
    "          SVC(kernel='poly'),\n",
    "          KNeighborsClassifier(n_neighbors=10),\n",
    "          KNeighborsClassifier(**params),\n",
    "          LinearDiscriminantAnalysis(store_covariance=True),\n",
    "          QuadraticDiscriminantAnalysis(store_covariance=True)]\n",
    "\n",
    "#cols=[\"Classifier\", \"Accuracy\"]\n",
    "sod1_rfe_class = []\n",
    "for model in models:\n",
    "    clf = Pipeline(steps=[('scaler', scaler),('m',model)])\n",
    "    clf.fit(train_final_rfe, y)\n",
    "    name = model.__class__.__name__\n",
    "    print(\"=\"*60)\n",
    "    print(name)\n",
    "    print('****Results****')\n",
    "    test_predictions = clf.predict(test_final_rfe)\n",
    "    acc = accuracy_score(y_test, test_predictions)\n",
    "    sod1_rfe_class.append(acc)\n",
    "    print(\"Accuracy: {:.4%}\".format(acc))\n",
    "    print(classification_report(y_test, test_predictions))\n",
    "    plot_cm(y_test, test_predictions, label_dict)\n",
    "    plt.show()\n",
    "    #entry = pd.DataFrame([[name, acc*100]], columns=log_cols)\n",
    "    \n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main difference is the steep decrease in accuracy of the QDA model. This could be due to the fact that QDA seem really sensitive to correlated features and SOD1 is correlated to sme of the other features. The other models perform similarly. \\\n",
    "Then we retrain the models with RFE selected variables and no correlated features with also SOD1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_nocor_sod1 = [x for x in features_def if x not in list(removed_columns)]\n",
    "\n",
    "train_final_rfe_nocor = train[features_nocor_sod1]\n",
    "test_final_rfe_nocor = test_final[features_nocor_sod1]\n",
    "\n",
    "pipe = Pipeline(steps=[('scaler', scaler),('m',grid_search_KNN)])\n",
    "\n",
    "pipe.fit(train_final_rfe_nocor, y)\n",
    "print(grid_search_KNN.best_params_ ) \n",
    "print('Best Score - KNN:', grid_search_KNN.best_score_ )\n",
    "params = grid_search_KNN.best_params_\n",
    "knn_opt = KNeighborsClassifier(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fig6.2'></a>\n",
    "#### Fig. 6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "models = [LogisticRegression(),\n",
    "          SVC(kernel='linear'),\n",
    "          SVC(kernel='poly'),\n",
    "          KNeighborsClassifier(n_neighbors=10),\n",
    "          KNeighborsClassifier(**params),\n",
    "          LinearDiscriminantAnalysis(store_covariance=True),\n",
    "          QuadraticDiscriminantAnalysis(store_covariance=True)]\n",
    "\n",
    "#cols=[\"Classifier\", \"Accuracy\"]\n",
    "sod1_rfe_nocor_class = []\n",
    "for model in models:\n",
    "    clf = Pipeline(steps=[('scaler', scaler),('m',model)])\n",
    "    clf.fit(train_final_rfe_nocor, y)\n",
    "    name = model.__class__.__name__\n",
    "    print(\"=\"*60)\n",
    "    print(name)\n",
    "    print('****Results****')\n",
    "    test_predictions = clf.predict(test_final_rfe_nocor)\n",
    "    acc = accuracy_score(y_test, test_predictions)\n",
    "    sod1_rfe_nocor_class.append(acc)\n",
    "    print(\"Accuracy: {:.4%}\".format(acc))\n",
    "    print(classification_report(y_test, test_predictions))\n",
    "    plot_cm(y_test, test_predictions, label_dict)\n",
    "    plt.show()\n",
    "    #entry = pd.DataFrame([[name, acc*100]], columns=log_cols)\n",
    "    \n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same disocurse applies for these models. \\\n",
    "We then create a dataset with all the test accuracies studied until now to visualize them in a barplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sod1_rfe_class = np.array(sod1_rfe_class).reshape(1,-1)\n",
    "sod1_rfe_nocor_class = np.array(sod1_rfe_nocor_class).reshape(1,-1)\n",
    "\n",
    "values = np.concatenate((sod1_rfe_class,sod1_rfe_nocor_class))\n",
    "rows = ['sod1+rfe', 'nocorr+rfe+sod1']\n",
    "\n",
    "df_acc2 = pd.DataFrame(values, columns=names, index=rows)\n",
    "df_acc2 = df_acc2.reset_index().rename(columns={'index': 'features'})\n",
    "df_acc2 = df_acc2.melt(id_vars='features', var_name='model', value_name='acc')\n",
    "df_def = pd.concat([df_acc, df_acc2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fig6.3'></a>\n",
    "#### Fig. 6.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9,4))\n",
    "ax.yaxis.grid(True)\n",
    "sns.barplot(x=\"features\", y=\"acc\", hue=\"model\", edgecolor = 'k',\n",
    "            palette=sns.color_palette(\"Set2\", 7), \n",
    "            data=df_def)\n",
    "plt.legend(bbox_to_anchor=(1.05, 0.7), loc=2, borderaxespad=0.)\n",
    "plt.ylim(0, 1)\n",
    "ax.set_title('Test Accuracy for different algorithms')\n",
    "ax.set_ylabel('Test Acc.')\n",
    "ax.set_yticks(np.arange(0,1.1,0.1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test performances of the classifiers do not seem to particularly increase adding SOD1 to the model. Using RFE features only KNN-optimized seems to be a little better. SOD1 however greatly reduces the performance of QDA when rfe and no correlated features are used to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Sod_rank.loc[features_def].sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(Sod_rank.loc[features_nocor_sod1].sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, if we check how much the other selected features are correlated with SOD1 we can see that they comprise the 2nd and 4th most correlated proteins. A decrease in performance of QDA is therefore understandable as we haeve seen that it is very sensitive to multicollinearity. Furthermore even if it seemed that SOD1 might have been an informative protein for this reason the performance of the other classifiers do not particularly increase as the information contained in SOD1 is more or less explained by its correlated features which were already present in the model.\n",
    "\n",
    "\n",
    "<a id='section_7'></a>\n",
    "# 7. Discussion\n",
    "\n",
    "Overall, the main characteristic that seems to influence protein expression in the brain cortex of mice seems to be the stimulus to learn, or fear arguably. Trisomic mice protein expression structure appeared more complex than control mice and memantine never give the impression of being an important condition in protein expression changes. Clustering these data therefore does not produce completely satisfying results with the algorithms we used. But our results almost overlap with the paper results. Performing SOM would be the perfect completion of this project.\n",
    "\n",
    "Some classification algorithms perform really well on the dataset managing to classify correctly almost all the test data. This \n",
    "however it is not so useful because in these kind of studies classification is usually not of great concern. Given that obtaining these kinds of data, especially regarding proteins, is costly and complex and classes are always known. It is more important to understand how belonging to these classes influnces the proteins \"landscape\".  \n",
    "\n",
    "Imputing the missing column of SOD1 in the test set gives discrete results. The final regression model chosen seems to explain the greater part of the variabilty of this protein, however leaving some 20/25% of it unexplained. SOD1 is a variable protein especially between SC and CS classes but adding it to the classification model does not increase the accuracy because it's correlated to other important proteins.\n",
    "\n",
    "\\\n",
    "In conclusion, this project shows satisfying results both in terms of classification tasks and reproducibility of the previously mentioned paper. This project could also be useful as a blueprint for analysis of these kind of data.\n",
    "\n",
    "\n",
    "\\\n",
    "\\\n",
    "\\\n",
    "\\\n",
    "\\\n",
    "Thank you for your attention, \n",
    "<font size=\"5\"><div style=\"text-align: right\"> Giacomo Mutti </div></font>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
